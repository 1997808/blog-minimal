[{"frontmatter":{"title":"Website analytics platform for bloggers and content creators","description":"Here's a look at why we created Plausible Analytics as a great Google Analytics alternative for content creators and their personal websites and blogs.","date":"2023-04-04T00:00:00.000Z","image":"/images/posts/01.jpg","categories":["development"],"authors":["Khanh Duy Le"],"tags":["Plausible","Google Analytics"],"draft":false},"content":"\nMany people create content on their personal websites and blogs. There are many motivations behind this. Some use it like a diary, some as a hobby, or as a way to connect to other people, as a way to build an audience, make money and even improve their career opportunities. \n\nFor some of these content creators, external recognition is not that important. They write what they want, about things they are interested in and they publish whatever they please. The fun is in the writing and the creative process itself.\n\nOthers like to understand the impact that their efforts have on the world, which posts bring in the readers, what topics people seem to enjoy the most and even how people end up discovering their content in the first place.\n\n![Website analytics for bloggers and content creators](https://storage.googleapis.com/support-kms-prod/Z2xIkRrq4V2vmeRtcDkeYRozBSJmaHRzuxRI \"Website analytics for bloggers and content creators\")\n\n## Web analytics give you a strong signal\n\nThis helps motivate them to put even more effort, publish more of the content that people enjoy the most and create a better website experience in general.\n\nAnd this is where website analytics come into the picture. Web analytics give website owners and bloggers a strong signal on what they have achieved, what worked well and what not so well. This helps them improve and better organize their future efforts. \n\nGoogle Analytics is the obvious and the default choice for most websites. Even though it is a very useful and powerful tool used on the majority of websites on the web, it [brings several issues](https://plausible.io/blog/remove-google-analytics) that distract site owners from what they enjoy doing the most. \n\nHere's a look at why we created Plausible Analytics as a great [Google Analytics alternative](https://plausible.io/vs-google-analytics) for content creators and their personal websites and blogs.\n\n## Google Analytics is complicated to use and understand\n\nGoogle Analytics collects so much data from website visitors that it can showcase more than 125 different reports and almost 300 individual metrics. You as a site owner will rarely have a need for more than a handful of these. This makes Google Analytics an overkill for the majority of bloggers.\n\nMany try to simplify Google Analytics by creating custom reports and custom dashboards. Some even take Google Analytics training courses in order to learn how to use it, how to understand the different metrics and extract actionable insights from them.\n\nIf you just want to publish content and interact with people, learning about analytics is not something you put on top of your priority list. So you end up ignoring Google Analytics. You keep it installed on your site and it keeps tracking your visitors but you don't really get much value from it.\n\nPlausible Analytics is built with [simplicity in mind](https://plausible.io/simple-web-analytics). Anyone can understand all the metrics we present at a glance and without having any training or prior analytics experience. Everything you need to know is on one page.\n\nYou can get an overview of all the most actionable metrics in one minute and get on with tasks that you enjoy more such as creating new content or engaging with your audience.\n\n## Google Analytics requires a privacy policy, cookie prompt and user consent\n\nThere are several requirements for using Google Analytics. Some from Google's side and others from the different privacy regulations.\n\nGoogle for instance [requires](https://marketingplatform.google.com/about/analytics/terms/us/) you to have a privacy policy with details on your usage of Google Analytics. \n\n> “You must post a Privacy Policy and that Privacy Policy must provide notice of Your use of cookies, identifiers for mobile devices or similar technology used to collect data. You must disclose the use of Google Analytics, and how it collects and processes data. You will use commercially reasonable efforts to ensure that a User is provided with clear and comprehensive information about, and consents to, the storing and accessing of cookies or other information on the User’s device where such activity occurs in connection with the Service and where providing such information and obtaining such consent is required by law.”\n\nOn top of this, Google Analytics places [multiple cookies](https://developers.google.com/analytics/devguides/collection/analyticsjs/cookie-usage) on the machines of your visitors which means that you need to ask for cookie consent from your visitors too.\n\nThese are things that many site owners and bloggers simply don't want to nor have the time or capacity to deal with. And the value that Google Analytics provides may not be worth it in terms of what it takes to have it running with regards to dealing with privacy policy and cookie consent.\n\nPlausible Analytics is compatible with the different privacy regulations such as GDPR, CCPA and PECR out of the box. [We don't use cookies](https://plausible.io/data-policy) and we don't collect any personal data from your visitors either. This means that you don't need to have a privacy policy regarding Plausible Analytics and you don't need to have a cookie banner nor ask to get consent from your visitors.\n\nYou keep your site simple, clean and optimized for your visitors. No need to put any time and effort into legal aspects. You can focus on the more creative side of things.\n\n## Google Analytics slows down your site and worsens the visitor experience\n\nGoogle Analytics is a bloated script that collects a lot of unnecessary data and it's not useful for the majority of site owners. This can lead to your site having slower loading times. It is common that the different speed tests including Google's own PageSpeed Insights flag Google Analytics as one of the elements that slow down a site.\n\nThe recommended way to start tracking your website using Google Analytics is to install the Global Site Tag (gtag.js) tracking code on all of your pages. It weighs 28 KB and it downloads another file called the Google Analytics tag which adds an additional 17.7 KB to your page size. These two tracking scripts combined add 45.7 KB of page weight to each and every page load.\n\nEvery KB can make a difference if you want to optimize for speed. Plausible Analytics script [weighs less than 1 KB](https://plausible.io/lightweight-web-analytics). That’s more than 45 times smaller than the Google Analytics Global Site Tag. Your site will keep loading fast and your visitors will have a smooth experience. \n\n## Google Analytics is blocked by many web users\n\nGoogle Analytics is the most widely used tracking script on the web. This makes it a big target. Browsers such as Brave and Firefox block it, so do the different ad-blocking extensions such as the uBlock Origin. \n\nThese are used by millions of web users who won't be counted in your website statistics. It's not uncommon to see 40% or even more of the audience on a tech website blocking Google Analytics.\n\nPlausible Analytics is a new player on this market and it's privacy-friendly by default, so it doesn't see the same level of blockage. We also have a proxy that allows you to run our script as a [first party connection from your domain name](https://plausible.io/docs/proxy/introduction). You may very well see more accurate (and higher) visitor numbers.\n","slug":"post-1"},{"frontmatter":{"title":"Umami - The Better Google Analytics Alternative","description":"Find out why Umami is the best GA alternative.","date":"2024-04-30T00:00:00.000Z","image":"/images/posts/02.jpg","categories":["development"],"authors":["Khanh Duy Le"],"tags":["Umami","Google Analytics"],"draft":false},"content":"\nBoth businesses and personal users need to understand their website data to gain insights into how their customers, users, and visitors engage with their content. Google Analytics provides these insights into website traffic, but its practices raise concerns about user privacy and data protection. Like most Google products, Google Analytics is free because Google collects all sorts of data and then uses it to make money in its other products, like Google Ads.\n\nThis blog post explores how Google Analytics works, the privacy implications regarding the data it collects and how it uses it, and why Umami is a suitable privacy-first alternative.\n\n# How Google Analytics Works\n\nTo use Google Analytics, website owners have to first create an account and then add a tracking code to their website. The tracking code collects user behavior data, including the user's IP address, device, browser, and location. Google Analytics uses cookie-based tracking to monitor users across different sessions and to identify unique users.\nWhat Data Does Google Analytics Collect?\nGoogle Analytics collects various data about a user's behavior on a website. Such as:\n\n1. **User location**: Google Analytics can track a user's location based on their IP address. This allows website owners to see where their visitors are coming from and can help them tailor their content to specific regions.\n2. **Device type**: Google Analytics can track the user's device (i.e., desktop, iPhone, tablet, etc). This includes information about the user's operating system, browser, and screen size.\n3. **User behavior**: Google Analytics tracks what users do on a website, such as page visits, time on site, and actions they perform (such as filling out a form, clicking a button, etc.). With specific settings enabled, Google Analytics can also track things like scroll depth.\n4. **Referral source**: Google Analytics can track how users find the website, whether through a search engine, social media, clicking a link in an email, a paid advertisement, or another website.\n5. **Demographic information**: Google Analytics can provide demographic information about users, such as age, gender, and interests.\n\nGoogle can also source and combine data from other Google services like Search and YouTube and share it back to Google Analytics. Google states in Data Share Settings sections of the Google Analytics docs that, “Google products & services: When you turn this setting ON, Google can access and analyze data to better understand online behavior and trends, and use this data to improve Google products and services.”\n\n# How Does Google Analytics Use This Data?\n\nGoogle Analytics uses the data it collects on website visitors and creates profiles for them, which advertising can use as targeting criteria in their Google Ads campaigns. For example, if a user is identified as being interested in a particular topic (such as networking software), they may be shown ads related to that topic.\n\nGoogle can bucket users into two categories: Affinity or In-Market. Affinity means the user is generally interested in a topic, and In-Market suggests the user is in the market to make a purchase. Google aggregates your actions online - not just from your website activity on Google Analytics - to create a profile for you. If a user visits a website about a new Honda, gets directions to the Honda dealership in Google Maps, visits websites about auto financing, and watches YouTube videos about Honda reviews, Google will bucket you as someone in the market to purchase a new car.\n\nAlthough this type of advertising can work because it is based on the user's interests and behavior, it can feel unsavory that Google is tracking everything you're doing and bucketing you into categories. How would you feel if I stood over your shoulder watching and writing down everything you did, everywhere you went, and then used that information to sell something to you? We probably wouldn't be friends.\n\nThere are concerns about this data regarding user privacy, such as:\n\n- Users might not know this data is being tracked\n- Users should be informed that this data is being collected\n- Users should have to give their consent for their data to be used in this way\n\nAnother concern is that the data collected by Google is only sometimes correct, which can lead to false assumptions about users' behavior.\n\n# Privacy Implications of Using Google Analytics\n\nUsing Google Analytics raises questions about user consent and control over their personal information. Many users likely don't know the extent of the data collection and the implications of allowing Google Analytics to track their online activity. This lack of transparency and control over personal data goes against privacy and data protection principles.\n\nThe potential for data breaches on the information collected by Google Analytics is a concern. Users entrust their browsing behavior and personal details to website owners, who are responsible for safeguarding this data. However, reliance on third-party services like Google Analytics introduces additional security risks that may compromise user privacy.\n\n# What Can Website Owners Do to Protect User Privacy?\n\nWebsite owners should prioritize transparency and user consent when implementing tracking tools like Google Analytics. Respecting user privacy and providing clear information about what data is being collected can help build trust and foster a more ethical approach to website analytics.\n\nOne way to do this is to provide users with a clear and prominent privacy policy that explains what data is collected, why it is collected, and how it is used. Website owners should also give users the option to opt out of data collection if they choose to do so. This typically comes in the form of cookie opt-in/opt-out banners, where users need to click a button to be tracked.\n\nAnother option is to use an alternative analytics tool that prioritizes user privacy. Privacy-focused website analytics tools, such as Umami, are now commonly available. Umami offers [similar features](/features) to Google Analytics but with a significantly greater focus on user privacy. Umami is a cookie-free website analytics platform that does not require those annoying opt-in cookie banners.\n\nUmami has two versions: self-hosted and cloud. Both versions allow full data ownership since users can export all their data from Umami anytime. This can provide added security and peace of mind for businesses concerned about data privacy. On the other hand, Google Analytics stores data on Google's servers, which some companies may be uncomfortable with.\n\nThere are concerns with Google Analytics regarding user privacy and data protection. Website owners should prioritize transparency and user consent when implementing tracking tools like Google Analytics. Respecting user privacy and providing clear information about what data is being collected and how it is being used can help build trust and foster a more ethical approach to website analytics.\n\nTry [Umami](https://cloud.umami.is/signup?ref=umami-blog) today, which makes it easy to collect, analyze, and understand your web data while maintaining visitor privacy and data ownership.","slug":"post-2"},{"frontmatter":{"title":"Virtual Machine Detection In The Browser","description":"This blog post covered four unique VM detection capabilities that can be performed from Javascript","date":"2022-06-02T00:00:00.000Z","image":"/images/posts/03.jpg","categories":["development"],"authors":["bannedit's musings"],"tags":["VM","Javascript"],"draft":false},"content":"\n### Introduction\n\nVirtual Machine (VM) detection is nothing new. Malware has been doing it for over a decade now. Over time the techniques have advanced as defenders learned new ways of avoiding VM detection.\n\nA while back a friend and I were working on a project related to exploit delivery via a web application for redteaming purposes. I wanted a way to fingerprint visitors of the site and hash the fingerprint data so I could look for potential repeat visitors. While investigating fingerprinting I stumbled upon something pretty interesting. I was looking at some code that collected information about WebGL capabilities. I quickly realized that some of the fingerprinting information could be useful for VM detection because vendor names were exposed. In this particular instance the string \"VMWare\" was contained within the WebGL information. After some more testing I also discovered that VirtualBox reported the same kind of information.\n\nOnce I realized it was potentially possible to detect VMs from the browser I started to dig deeper and began searching for other research related to this discovery. I found a pretty well researched academic paper [\\[1\\]](http://yinzhicao.org/TrackingFree/crossbrowsertracking_NDSS17.pdf) related to tracking users across multiple browsers. This gave me some other potential techniques that could be applied to VM detection.\n\nThe end goal of this research is to have multiple techniques for VM detection. Multiple techniques lead to much more accurate detection. Since some techniques are more false-positive prone than others, a weighting system can be applied to the detection capabilities. This allows us to generate detection confidence scoring. This can help account for inaccuracies of certain detection methods. Given enough testing and data it would then be possible to come up with a reasonable threshold value. If a browser scores above the threshold then it would most likely be within a VM. Alternatively, if the browser scored below the threshold value it could be considered to be running on physical hardware.\n\n### Techniques\n\nNow that I have covered some of the background information and history leading up to this blog post we can start to dig into the actual techniques.\n\nAs mentioned prior in the introduction, WebGL can provide a lot of information about the OpenGL implementation including vendor information. The WEBGL\\_debug\\_renderer\\_info extension [\\[2\\]](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_debug_renderer_info) can be used to query for debug information such as the WebGL vendor and rendered.\n\n```javascript\nvar canvas \\= document.createElement('canvas');\nvar gl \\= canvas.getContext('webgl');\n\nvar debugInfo \\= gl.getExtension('WEBGL\\_debug\\_renderer\\_info');\nvar vendor \\= gl.getParameter(debugInfo.UNMASKED\\_VENDOR\\_WEBGL);\nvar renderer \\= gl.getParameter(debugInfo.UNMASKED\\_RENDERER\\_WEBGL);\n\nconsole.log(vendor);\nconsole.log(renderer);\n```\n\nAdditionally, extension availability can be queried using the **_getExtension_** method on a WebGL context. I have not fully explored this avenue but it might be possible to detect certain WebGL implementations provided by VMs based on the extensions available. Though this idea is likely very false-positive prone.\n\nBelow is a screenshot from [\\[3\\]](https://webglreport.com) WebGLReport a website dedicated to fingerprinting WebGL.\n\n![VirtualBox Windows 10 x64 VM Google Chrome Visiting webglreport.com](https://bannedit.github.io/resources/VirtualBox-VM-Win10-Chrome.png) \n> ***VirtualBox Windows 10 x64 VM Google Chrome Visiting webglreport.com***\n\nNow, it is important to note that this depends on how the VM is configured. In Virtual Box for example, setting the graphics controller setting under Display to VMSVGA will report cause WebGL to use CPU based implementations of OpenGL which is browser dependent. However, this could still be a useful indicator that the client machine is running in a VM because most modern hardware has integrated GPUs and can provide access to OpenGL natively. Just keep in mind that CPU based OpenGL implementations do not necessarily mean it is a VM outright.\n\n![VirtualBox Windows 10 x64 VM Google Chrome Using VMSVGA](https://bannedit.github.io/resources/VirtualBox-VM-Win10-Chrome-VMSVGA.png) \n> ***VirtualBox Windows 10 x64 VM Google Chrome Using VMSVGA***\n\nThis screenshot depicts Google Chrome utilizing the CPU based OpenGL implementation renderer Google SwiftShader [\\[4\\]](https://github.com/google/swiftshader).\n\nAnother technique seen in normal malware is to determine the screen width and height. This can be achieved in Javascript as well. Additionally, color depth and bits per pixel are other potentially good indicators related to the display.\n\n```javascript\nvar width \\= screen.width;\nvar height \\= screen.height;\nvar color\\_depth \\= screen.colorDepth;\nvar bitspp \\= screen.pixelDepth;\n```\n\nMore details on the screen object can be found at [\\[5\\]](https://www.w3schools.com/jsref/obj_screen.asp).\n\nCan we detect the amount of RAM on the client? You bet. Again using Javascript we can determine roughly the amount of RAM available on the browser. One quirk to note here is that the browser will only report RAM values in gigabytes (gb). It also has a quirk where it will only report up to 8gb and as low as 256mb (0.25gb). These ranges of values however, are still enough to use as a VM detection method. Most physical workstations these days come with at least 8gb of RAM. Detecting smaller amounts of RAM such as 2gb or less would be a good indicator the client browser is in a VM. The specification for the Device Memory can be found at [\\[6\\]](https://www.w3.org/TR/device-memory/)\n\nvar ram \\= navigator.deviceMemory;\n\nFinally, the last technique I will be covering detects the number of CPU cores. This is done by performing timing attacks using multiple web workers running simultaneously. During my testing of this technique I found it to be very accurate. I tested this concept out using the [\\[7\\]](https://oswg.oftn.org/projects/core-estimator/demo/) Core Estimator Demo site. A small number of CPU cores can be a decent VM indicator and has been used by malware in the past. Core Estimator also provides the Javascript libraries on github [\\[8\\]](https://github.com/oftn-oswg/core-estimator).\n\n![VirtualBox Windows 10 x64 VM Chrome With 2 CPU Cores](https://bannedit.github.io/resources/VirtualBox-VM-Win10-Chrome-2-Cores.png) \n> ***VirtualBox Windows 10 x64 VM Chrome With 2 CPU Cores***\n\n### Conclusion\n\nThis blog post covered four unique VM detection capabilities that can be performed from Javascript. When I first discovered these techniques my initial thought was to apply the concepts toward VM detection. Hopefully, both defenders and offensive security professions can find something useful to apply these techniques toward.\n\nIt is interesting to see that academics and various other researchers have applied some of the same concepts toward fingerprinting and privacy issues.\n\n### References\n\n1.  (Cross-)Browser Fingerprinting via OS and Hardware Level Features [http://yinzhicao.org/TrackingFree/crossbrowsertracking\\_NDSS17.pdf](http://yinzhicao.org/TrackingFree/crossbrowsertracking_NDSS17.pdf)\n    \n2.  MDN web-docs WEBGL\\_debug\\_renderer\\_info [https://developer.mozilla.org/en-US/docs/Web/API/WEBGL\\_debug\\_renderer\\_info](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_debug_renderer_info)\n    \n3.  WebGL Report [https://webglreport.com](https://webglreport.com)\n    \n4.  Google Swiftshader Github [https://github.com/google/swiftshader](https://github.com/google/swiftshader)\n    \n5.  W3 Device Memory Specification [https://www.w3.org/TR/device-memory/](https://www.w3.org/TR/device-memory/)\n    \n6.  W3 Schools - The Screen Object [https://www.w3schools.com/jsref/obj\\_screen.asp](https://www.w3schools.com/jsref/obj_screen.asp)\n    \n7.  Core Estimator Demo [https://oswg.oftn.org/projects/core-estimator/demo/](https://oswg.oftn.org/projects/core-estimator/demo/)\n    \n8.  Core Estimator Github [https://github.com/oftn-oswg/core-estimator](https://github.com/oftn-oswg/core-estimator)","slug":"post-3"},{"frontmatter":{"title":"How to Build a Bot Detection Script From Scratch: A Step-by-Step Guide","description":"Bot Detection","image":"/images/posts/09.png","date":"2024-06-12T00:00:00.000Z","draft":false,"authors":["Khanh Duy Le"],"tags":["Bot","Web"],"categories":["Javascript"]},"content":"\nDid you know an estimated half of all web traffic comes from bots? And over half of that automated traffic is from \"bad bots.\" Websites constantly face threats from automated bots designed to carry out malicious activities like credential stuffing attacks, web scraping, spam distribution, and fraud.\n\nAccurately distinguishing this automated bot traffic from genuine human traffic is critical to protecting websites, user data, and online assets. As these bots continue to evolve, businesses must add robust measures to detect and mitigate bot attacks effectively and keep up with the latest bot technology.\n\nMany methods exist to identify potential bot activity, whether you are analyzing network and traffic patterns, user browsers and device information, or behavior patterns. These methods allow you to take immediate action and prevent data breaches, protect user privacy, and ensure the integrity of your website.\n\nThis step-by-step guide for client-side bot detection explores common techniques for identifying bot activity. By the end of this tutorial, you'll have gained hands-on experience in building a basic bot detection script and learn practical methods to distinguish human visitors from malicious bots and protect your site.\n\nUnderstanding bots\nBots are automated programs that can execute tasks and interactions over the internet by mimicking human behavior. These programs visit websites and apps and perform predefined actions, usually in a “headless” mode without a graphical interface.\n\nOn the one hand, bots facilitate many legitimate functions, such as web crawling for search engines, data collection for research, website performance monitoring, and automating repetitive online tasks.\n\nHowever, bad actors can also use bots for malicious purposes, such as trying countless username/password combinations, illicitly scraping proprietary data or copyrighted content, launching distributed denial of service (DDoS) attacks, and spreading spam or malware.\n\nFundamentals of bot detection\nBot detection strategies can be broadly categorized into server-side and client-side techniques, each harnessing different methods to identify and manage bot traffic.\n\nServer-side detection uses your backend to analyze data like IP addresses, HTTP headers, and session durations. Common methods include:\n\nIP Blocklists: Checking user IP addresses against lists of known IPs or bot networks associated with malicious activity.\nRate Limiting: Monitoring the frequency of requests to identify and mitigate unusually high traffic from single sources, usually indicative of bots.\nBehavioral Analysis: Assessing access and interactions over time to detect anomalies in behavior that deviate from human patterns.\nClient-side detection operates within the user's browser and analyzes user behaviors and environmental data in real-time. Some client-side methods include:\n\nCAPTCHAs: Challenges that differentiate bots from humans by asking visitors to do tasks that are trivial for humans but difficult for bots.\nBrowser Analysis: Gathering and analyzing browser configurations and capabilities to identify patterns or inconsistencies typical of automated scripts.\nBehavioral Analysis: Monitoring actions like mouse movements, keystrokes, and interaction timings to detect non-human activity.\nThis guide will focus on client-side techniques, mainly how scripts can analyze the inadvertent data bots emit as they interact with a webpage. These leaks may manifest as anomalies in interaction patterns, browser settings, or how a page's layout is processed. By examining these factors, we can develop scripts that identify potential bots. This approach allows for rapid, on-the-spot bot detection, enhancing user experience by minimizing intrusive checks and maintaining performance efficiency.\n\nBuilding a basic bot detection script\nLet's start building a basic bot detection script for a sample application. This tutorial will use vanilla JavaScript to keep it accessible to a broad audience and various web environments. The objective of our application is simple: to analyze specific data from the visitor's browser to determine whether they are likely a bot. We'll do this by collecting data, analyzing them against common bot patterns, and sending a message in the application indicating if the script detected a bot. This example will showcase how client-side scripts can assess environmental signals to make this distinction and will not include server-side processing.\n\nPrerequisites\n\nTo follow along with the tutorial locally, you must have Node.js installed on your machine and a code editor like Visual Studio Code. You can also use a cloud development environment like Stackblitz or CodeSandbox.\n\nSet up the sample web application\nTo begin creating our bot detection script, we first need a simple web application where we will integrate it.\n\n1. Create the project structure\n\nStart by creating a new directory for your project. Inside this directory, create the following files:\n\nindex.html: This will be the main HTML document.\nscript.js: This JavaScript file will hold our bot detection logic.\nYour project directory should look like this:\n\n```javascript\nbot-detection-app/\n|-- index.html\n|-- script.js\n```\n\n1. Set up the HTML file\n\nOpen the index.html file and set up the basic HTML structure, including linking to the script.js file. We’ll be using tailwind for some simple styling. Here’s a simple template to start with:\n\n\n``` html\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <link\n      rel=\"icon\"\n      href=\"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%221em%22 font-size=%2280%22>🤖</text></svg>\"\n    />\n    <title>Simple Bot Detection App</title>\n    <script src=\"https://cdn.tailwindcss.com\"></script>\n    <script src=\"script.js\" defer></script>\n  </head>\n  <body class=\"bg-gray-100 text-gray-900 min-h-screen pt-20 text-center\">\n    <h1 class=\"text-4xl font-bold mb-4\">🤖</h1>\n    <h1 class=\"text-2xl font-bold mb-4\">Bot Detection Sample Application</h1>\n    <div id=\"result\" class=\"text-xl font-medium\"></div>\n  </body>\n</html>\n```\n\n1. Serve and preview the application\n\nYou can use a simple HTTP server to run the sample web application locally and preview it in your browser. A simple way to do this is with http-server, an easy-to-use zero-configuration command-line HTTP server great for quickly serving static files. First, install the package:\n\nnpm install -g http-server\nThen navigate to your project directory in the terminal and run:\n\nhttp-server\nNote: You can also install this as a local project dependency with npm install http-server and run it with npx http-server instead.\n\nThe HTTP server will serve your project, making it available at http://localhost:8080. Open this URL in your browser to view the application as you work.\n\nWith these steps completed, you have set up a simple web application that is ready to implement bot detection functionalities. This setup will allow us to focus now on collecting data and determining if a visitor might be a bot in the upcoming sections of the tutorial.\n\nCollect and analyze visitor data\nIn this section, we'll focus on collecting data that we will use to determine if a visitor might be a bot. We will gather browser characteristics often exploited or modified by bots that serve as good indicators. Create a new detectBot function with a detectors object to store each detected signal.\n\n```javascript\nfunction detectBot() {\n  const detectors = {};\n}\n```\n\n1. Detect WebDriver automation\n\nOne of the simplest places to find signals for bot detection is to look at the Navigator object. This object is a part of the Window interface and represents the state and identity of the user's browser. It has information about the browser itself, including its version, the operating system it's running on, and various capabilities of the browser environment.\n\nWithin the navigator object, the webdriver property is especially useful as it indicates whether the browser is being controlled by automation tools such as Selenium, Puppeteer, or other automated testing frameworks. Unlike many other indicators that require interpretation or analysis, these tools typically set the navigator.webdriver property to true to indicate automation control. Add this property to the detectors object.\n\n```javascript\nfunction detectBot() {\n  const detectors = {\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\n  };\n}\n```\n\nAs we progress, we will add more properties to the detectors object to collect additional data from different aspects of the visitor's environment that may indicate bot activity. Starting with navigator.webdriver establishes a solid foundation for recognizing the most obvious automated interactions.\n\n1. Look for Headless Chrome\n\nThe navigator.userAgent property is another valuable piece of data for bot detection. This user agent string identifies the browser, its version, the underlying operating system, and sometimes other details about the device. Looking at the user agent can help determine whether the traffic originates from common headless browsers that might be used for scraping, automation, or other scripted activities. Add a check for the user agent that looks for “Headless”, a common value found in the most common tools used for automated tasks on the web. You can also check for other tools with string searches for values like “PhantomJS” or “Electron”.\n\n```javascript\nfunction detectBot() {\n  const detectors = {\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\n    headlessBrowser: navigator.userAgent.includes(\"Headless\"), // Detects headless browsers\n  };\n}\n```\n\nThe webdriver and userAgent properties can cover quite a large amount of bot activity already, but the more indicators you analyze, the more accurate your bot detection can become. Especially since many automation tools add features and settings that try to evade common bot detection techniques. Let’s continue to add a few more helpful detector examples.\n\n1. Check for missing preferred language\n\nOne potential indicator of a bot is the lack of set languages. The navigator.languages property returns a list of the user's preferred languages ordered by preference, with the most preferred language (first in the list) also set as the navigator.language property. However, the navigator.languages property sometimes returns an empty string in headless browsers. We’ll add the length of this property as a new signal for our bot detection.\n\n```javascript\nfunction detectBot() {\n  const detectors = {\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\n    headlessBrowser: navigator.userAgent.includes(\"Headless\"), // Detects headless browsers\n    noLanguages: (navigator.languages?.length || 0) === 0, // Checks if no languages are set, uncommon for regular users\n  };\n}\n```\n\n1. Evaluate expected browser features\n\nYou can also check the properties of JavaScript functions that are sometimes altered by automation scripts or in a headless environment. Bots can easily change user agent strings, so this check looks to see if there is a mismatch between the browser from the user agent and the features that should be available for that browser. For example, you can check the length of the eval function and compare it to what is expected for that browser.\n\nThis check requires more work, first detecting the browser and then comparing the appropriate length values. Let’s add a new function to do this check and use the returned result for our inconsistentEval detector.\n\n```javascript\nfunction detectBot() {\n  const detectors = {\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\n    headlessBrowser: navigator.userAgent.includes(\"Headless\"), // Detects headless browsers\n    noLanguages: (navigator.languages?.length || 0) === 0, // Checks if no languages are set, uncommon for regular users\n    inconsistentEval: detectInconsistentEval(), // Check for inconsistent eval lengths\n  };\n}\n\nfunction detectInconsistentEval() {\n  let length = eval.toString().length;\n  let userAgent = navigator.userAgent.toLowerCase();\n  let browser;\n\n  if (userAgent.indexOf(\"edg/\") !== -1) {\n    browser = \"edge\";\n  } else if (\n    userAgent.indexOf(\"trident\") !== -1 ||\n    userAgent.indexOf(\"msie\") !== -1\n  ) {\n    browser = \"internet_explorer\";\n  } else if (userAgent.indexOf(\"firefox\") !== -1) {\n    browser = \"firefox\";\n  } else if (\n    userAgent.indexOf(\"opera\") !== -1 ||\n    userAgent.indexOf(\"opr\") !== -1\n  ) {\n    browser = \"opera\";\n  } else if (userAgent.indexOf(\"chrome\") !== -1) {\n    browser = \"chrome\";\n  } else if (userAgent.indexOf(\"safari\") !== -1) {\n    browser = \"safari\";\n  } else {\n    browser = \"unknown\";\n  }\n\n  if (browser === \"unknown\") return false;\n\n  return (\n    (length === 33 && ![\"chrome\", \"opera\", \"edge\"].includes(browser)) ||\n    (length === 37 && ![\"firefox\", \"safari\"].includes(browser)) ||\n    (length === 39 && ![\"internet_explorer\"].includes(browser))\n  );\n}\n```\n\n1. Look for automation-related attributes\n\nSome automation tools add specific attributes to the DOM. Looking for these attributes can be useful for detecting specific automation tools, like Selenium, which may leave traces in the form of custom attributes. Let’s add another data point to our bot detection that gets the attributes of the document's root element and looks for properties commonly associated with automation tools.\n\n```javascript\nfunction detectBot() {\n  const detectors = {\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\n    headlessBrowser: navigator.userAgent.includes(\"Headless\"), // Detects headless browsers\n    noLanguages: (navigator.languages?.length || 0) === 0, // Checks if no languages are set, uncommon for regular users\n    inconsistentEval: detectInconsistentEval(), // Check for inconsistent eval lengths\n    domManipulation: document.documentElement\n      .getAttributeNames()\n      .some((attr) => [\"selenium\", \"webdriver\", \"driver\"].includes(attr)), // Looks for attributes commonly added by automation tools\n  };\n}\n```\n\nThese are just a handful of example signals that you can use to identify bots, and the more sophisticated the bot, the more signals you will need to check to detect it. Using this data, let's look at how you can now detect if a visitor is a bot.\n\nDetect the presence of a bot\nAfter gathering the necessary data points about the visitor's environment, the next step is to analyze this information to determine whether the visitor is likely a bot. We can loop through each detector, and if a signal for a bot is found, we’ll record which detector was flagged and set our bot verdict to true.\n\n```javascript\nfunction detectBot() {\n  const detectors = {\n    …\n  };\n\n  // 1. Stores the detection results and the final verdict\n  const detections = {};\n  let verdict = { bot: false };\n\n  // 2. Iterates over the detectors and sets the verdict to true if any of them detects bot-like activity\n  for (const detectorName in detectors) {\n    const detectorResult = detectors[detectorName];\n    detections[detectorName] = { bot: detectorResult };\n    if (detectorResult) {\n      verdict = { bot: true }; // Sets the verdict to true at the first detection of bot-like activity\n    }\n  }\n\n  // 3. Returns the detection results and the final verdict\n  return { detections, verdict };\n}\n```\n\nThe new additions to the detectBot function:\n\nCreates variables to store the bot detection results and a verdict.\nLoops through each detector, and if a bot signal is found, it is added to the detections list and sets the verdict to true.\nReturns the list of detections and the final bot verdict.\nUse the bot detection result\nAt this point, you can decide how to handle the visitor based on your bot detection result. This tutorial will display the result on the page and log the detections and verdict in the console. Add the following after your function declarations.\n\n```javascript\nfunction detectBot() {\n\t...\n}\n\nfunction detectInconsistentEval() {\n\t...\n}\n\nconst { detections, verdict } = detectBot();\ndocument.getElementById('result').innerText = verdict.bot ? 'Bot detected' : 'No bot detected'; // Displays the detection result on the web page\nconsole.log(JSON.stringify(verdict, null, 2)); // Logs the final verdict\nconsole.log(JSON.stringify(detections, null, 2)); // Logs detailed detections\n```\n\nTest the bot detection\nNow, we can visit our page and see the result of our bot detection script. If you followed along locally, ensure the http-server is running and visit http://localhost:8080 in your browser. If you are using a cloud IDE, visit the preview page provided for your project. You should see the result “No bot detected” displayed on the screen. You can also see the verdict and details in the developer console.\n\nScreenshot of the final bot detection sample app\n\nNow, let’s test the script using a bot. Within your root folder in a new terminal, we’ll add Puppeteer to test our basic bot detection.\n\nnpm install puppeteer\nNext, create a new file called bot_test.js with the following code to run Puppeteer and test out your application.\n\n```javascript\nconst puppeteer = require(\"puppeteer\");\n\n(async function testBot() {\n  const url = \"http://localhost:8080\";\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  // Log console messages from the page\n  page.on(\"console\", (message) =>\n    console.log(`${message.type().toUpperCase()} ${message.text()}`)\n  );\n  await page.goto(url);\n  await page.close();\n  await browser.close();\n})();\n```\n\nIn this file, we use the Puppeteer library to launch a headless browser and navigate to your local application. You’ll notice there is a line to display any console messages from the page in your terminal to see the output of the verdict and detections. If you are following along in a cloud IDE, make sure to use the appropriate URL.\n\nNow that the script is ready, in your new terminal at the root, run the bot_test.js script.\n\nnode bot_test.js\nOptionally, you can use our instance of Browserless to visit your public-facing project link as a bot.\n\nYou will see the verdict and detections shown from the console log and should see an output similar to the one below that shows a bot was detected.\n\n```javascript\nLOG {\n\t\"bot\": true\n}\n\nLOG {\n  \"webDriver\": {\n    \"bot\": true\n  },\n\n  \"headlessBrowser\": {\n    \"bot\": true\n  },\n\n  \"noLanguages\": {\n    \"bot\": false\n  },\n\n  \"inconsistentEval\": {\n    \"bot\": false\n  },\n\n  \"domManipulation\": {\n    \"bot\": false\n  }\n}\n```\n\nThis sample tutorial simply displays the result of the bot detection, but you can easily incorporate the verdict into your application to decide how to handle the visitor.\n\nImproving your bot detection\nWhile the basic bot detection script provided earlier serves as an introduction to identifying automated traffic, it naturally has limitations that could affect its use in more demanding or varied environments:\n\nLimited Scope: The script checks only a handful of potential indicators, such as navigator.webdriver, user agent content for \"Headless\", and a few others. This narrow focus can miss more sophisticated bots that do not trigger these specific detectors.\n\nTool Specificity: Some of the checks, like looking for \"Headless\", are tailored to detect specific types of automation tools. While effective against those, they won't catch bots using different tools or customized solutions that don't modify the user agent string or use different mechanisms.\n\nBrowser Dependency: The detection techniques used can be highly dependent on the behaviors of specific browsers. Some indicators can have legitimate differences and variances with their implementations. Keeping up with these variations across updates and different browsers adds complexity and maintenance overhead.\n\nDynamic Web Ecosystem: Browsers and bot technologies evolve quickly. A method that works today might become obsolete tomorrow as both browsers update their features for privacy and security, and bot operators update their tools to evade detection.\n\nSuggestions for script improving accuracy\nTo boost the accuracy and reliability of your bot detection mechanisms, consider extending your script beyond basic checks. By combining different types of data points and detection methods, you can create a more robust defense against various bot activities. For example, integrating behavioral analysis—such as monitoring mouse movements, keystrokes, and even scrolling behaviors—can help identify bots that might otherwise pass more static checks. These behavioral signals are often more difficult for bots to convincingly mimic and can reveal the non-human characteristics of their interactions.\n\nAdditionally, keeping your detection methods up-to-date is essential. As browsers evolve and bot operators refine their techniques, your detection strategies must also adapt. Regular updates to your scripts to align with the latest browser versions and known bot signatures ensure that your detection mechanisms remain effective against current and emerging threats.\n\nUsing the open-source BotD library\nFor those looking to improve their bot detection capabilities without the burden of developing and maintaining a complex in-house system, the open-source BotD bot detection library presents a robust and user-friendly alternative.\n\nBotD provides more comprehensive coverage, incorporating more detection techniques that address multiple bot behaviors. Being an open-source library, it can easily be added to websites to increase defenses against bot traffic, minimizing the technical challenges typically associated with detecting bots.\n","slug":"post-4"},{"frontmatter":{"title":"Crafting a Uniform Response Structure in NestJS: A Guide to Mastering Interceptors","description":"Streamlining API Development with Powerful Interceptor Techniques","image":"/images/posts/05.jpg","date":"2024-07-02T00:00:00.000Z","draft":false,"authors":["Stackademic"],"tags":["NestJS","Javascript"],"categories":["Javascript"]},"content":"\nIn the rapidly evolving domain of web development, maintaining a uniform response structure plays a pivotal role in building a robust and scalable application, especially when it comes to creating an API ecosystem that interacts with various services and components. A uniform response structure not only ensures consistency across services but also facilitates enhanced error handling, easier maintenance, and efficient logging and monitoring. Before we delve into a hands-on demonstration, let’s discuss why having a uniform response structure is significant.\n\n### Significance of a Uniform Response Structure\n\nA uniform response structure stands as a cornerstone in constructing an efficient and seamless API experience. Here’s why it’s vital:\n\n1.  Consistency Across Services: It guarantees that every service communicates using a standard language, enhancing interoperability and facilitating a smoother integration process, particularly in microservices architectures.\n2.  Enhanced Error Handling: A standard response format means standardized error handling. It assists in crafting user-friendly error messages, improving the user experience by presenting clear and uniform error responses.\n3.  Ease of Maintenance and Scalability: As your application grows, maintaining a uniform response structure ensures that the integration of new features or services is seamless, preventing potential disparities in response formats and thereby reducing the maintenance overhead.\n4.  Efficient Monitoring and Logging: Uniform responses allow monitoring tools to be configured more effectively, helping in the setup of analytics and logging systems that provide critical insights into API performance and usage trends.\n\nUnderstanding its significance, let’s move forward to set up a uniform response structure using NestJS interceptors in our sample project.\n\n### Setting up Your NestJS Project\n\nBefore we start crafting our interceptor, let’s ensure that you have the necessary setup ready. Firstly, install the Nest CLI globally using the following command:\n\n```bash\nnpm install -g @nestjs/cli\n```\n\nNext, leverage the power of the Nest CLI to create a new project named `sample-interceptor-example` and navigate into your project directory as shown below:\n\nnest new sample-interceptor-example  \ncd sample-interceptor-example\n\n### Generating and Setting up the Interceptor\n\nWith your project setup ready, it’s time to create an interceptor. Generate a new interceptor named ‘response’ using the following command:\n\n```bash\nnest g itc response\n```\n\nThis command generates a boilerplate interceptor file with the following structure:\n\n```javascript\nimport { CallHandler, ExecutionContext, Injectable, NestInterceptor } from '@nestjs/common';  \nimport { Observable } from 'rxjs';  \n  \n@Injectable()  \nexport class ResponseInterceptor implements NestInterceptor {  \n  intercept(context: ExecutionContext, next: CallHandler): Observable<any\\> {  \n    return next.handle();  \n  }  \n}\n```\n\nNow, we will enhance this interceptor to handle both successful and erroneous responses uniformly.\n\n### Modifying the Interceptor\n\nLet’s modify the `intercept` method in our interceptor to pipe through our custom response and error handlers. Here is how you can do it:\n\n```javascript\n  intercept(context: ExecutionContext, next: CallHandler): Observable<unknown\\> {  \n    return next.handle().pipe(  \n      map((res: unknown) => this.responseHandler(res, context)),  \n      catchError((err: HttpException) => throwError(() => this.errorHandler(err, context)))  \n    );  \n  }\n```\n\nIn the above snippet, we are using the `map` operator to handle successful responses and the `catchError` operator to handle errors uniformly. Let's proceed to implement these handlers.\n\n### Implementing the Error Handler\n\nThe error handler is designed to catch any exceptions that occur during the request lifecycle and return a standardized error response. Here is how you can implement it:\n\n```javascript\n  errorHandler(exception: HttpException, context: ExecutionContext) {  \n    const ctx = context.switchToHttp();  \n    const response = ctx.getResponse();  \n    const request = ctx.getRequest();  \n  \n    const status = exception instanceof HttpException ? exception.getStatus() : HttpStatus.INTERNAL\\_SERVER\\_ERROR;  \n  \n    response.status(status).json({  \n      status: false,  \n      statusCode: status,  \n      path: request.url,  \n      message: exception.message,  \n      result: exception,  \n    });  \n  }\n```\n\nIn this method, we first retrieve the HTTP context and then determine the appropriate status code for the error. Next, we construct a standardized error response containing various details like the request URL, status code, and error message.\n\n### Implementing the Response Handler\n\nSimilarly, we will create a response handler to process successful responses uniformly. Here is the implementation:\n\n```javascript\n  responseHandler(res: any, context: ExecutionContext) {  \n    const ctx = context.switchToHttp();  \n    const response = ctx.getResponse();  \n    const request = ctx.getRequest();  \n  \n    const statusCode = response.statusCode;  \n  \n    return {  \n      status: true,  \n      path: request.url,  \n      statusCode,  \n      result: res,  \n    };  \n  }\n```\n\nThis method, much like the error handler, retrieves the HTTP context and constructs a standardized response with a success status, the request URL, status code, and the result data.\n\n### Integrating the Interceptor in Your Application\n\nAfter modifying and implementing the necessary handlers in our interceptor, we have the following combined code structure:\n\n```javascript\nimport { Injectable, NestInterceptor, ExecutionContext, CallHandler, HttpException, HttpStatus } from '@nestjs/common';  \nimport { Observable, throwError } from 'rxjs';  \nimport { catchError, map } from 'rxjs/operators';  \n  \n@Injectable()  \nexport class ResponseInterceptor implements NestInterceptor {  \n  intercept(context: ExecutionContext, next: CallHandler): Observable<unknown\\> {  \n    return next.handle().pipe(  \n      map((res: unknown) => this.responseHandler(res, context)),  \n      catchError((err: HttpException) => throwError(() => this.errorHandler(err, context)))  \n    );  \n  }  \n  \n  errorHandler(exception: HttpException, context: ExecutionContext) {  \n    const ctx = context.switchToHttp();  \n    const response = ctx.getResponse();  \n    const request = ctx.getRequest();  \n  \n    const status = exception instanceof HttpException ? exception.getStatus() : HttpStatus.INTERNAL\\_SERVER\\_ERROR;  \n  \n    response.status(status).json({  \n      status: false,  \n      statusCode: status,  \n      path: request.url,  \n      message: exception.message,  \n      result: exception,  \n    });  \n  }  \n  \n  responseHandler(res: any, context: ExecutionContext) {  \n    const ctx = context.switchToHttp();  \n    const response = ctx.getResponse();  \n    const request = ctx.getRequest();  \n  \n    const statusCode = response.statusCode;  \n  \n    return {  \n      status: true,  \n      path: request.url,  \n      statusCode,  \n      result: res,  \n    };  \n  }  \n}\n```\n\nNow, to make our interceptor work, we need to integrate it into our NestJS application. Open the `main.ts` file in your project and include the following line inside the `bootstrap` function:\n\n```javascript\napp.useGlobalInterceptors(new ResponseInterceptor());\n```\n\nWith this addition, our interceptor is now active globally across our application. Run your application and witness the transformation in the API response structure — it’s harmonized, clean, and efficient, ensuring a streamlined user experience and facilitating easier maintenance and scalability.\n\n### Conclusion\n\nStepping back and evaluating what we’ve built, it’s clear to see the tangible benefits that implementing a uniform response structure can bring to a NestJS project. It streamlines the development process, facilitates debugging, and fosters a cleaner, more maintainable codebase.\n\nAs you continue your journey with NestJS, keep exploring its robust ecosystem and making the most of tools like interceptors. They not only tidy up your code but also prepare you for scaling your project in a manageable way. With a consistent response structure in place, you’ll find it easier to develop, maintain, and evolve your application effectively.\n\nHappy coding!\n\n### Stackademic\n","slug":"post-5"},{"frontmatter":{"title":"Lịch Đăng Ký Thi Năng Lực Tiếng Nhật Tháng 12.2024 Tại Điểm Thi Hà Nội","description":"meta description","image":"/images/posts/jlpt_2024.jpg","date":"2024-07-24T00:00:00.000Z","draft":false,"authors":["Khanh Duy Le"],"tags":["JLPT","Test","Năng Lực Tiếng Nhật"],"categories":["Education"]},"content":"\n1\\. Thời gian mua và nộp hồ sơ:\n\nN3, N4, N5: Bắt đầu từ ngày 15/07/2024 – 30/08/2024\n\n( Những đơn vị ở xa, mua nhiều hồ sơ có thể liên hệ sđt 0975 530 196 để được hỗ trợ gửi ship)\n\n2.Địa điểm mua hồ sơ:\n\nPhòng 102 khu liên hợp thể thao, Trường ĐH Ngoại Ngữ - ĐH Quốc Gia HN (Số 1, Phạm Văn Đồng, Cầu Giấy, Hà Nội)\n\nGiá bán: 30.000 / 1 hồ sơ \n\n3\\. Lệ phí nộp hồ sơ:\n\nN3, N4, N5: 620,000/ 1 hồ sơ\n\n4\\. Địa điểm nhận hồ sơ:\n\n\\-N3, N4, N5: Phòng 102, Khu liên hợp thể thao. Trường ĐH Ngoại Ngữ - ĐH Quốc Gia HN (Số 2, Phạm Văn Đồng, Cầu Giấy, Hà Nội)\n\n( Là tòa nhà trong khu vực sân bóng của trường. Thí sinh đi theo cổng Phạm Văn Đồng vào, sân bóng ở ngay phía bên tay trái cổng)\n\n5\\. Thời gian thi: 8h sáng chủ nhật ngày 01/12/2024\n\n6.Địa điểm thi:\n\n\\- N3, N4, N5: Trường ĐH Ngoại Ngữ - ĐH Quốc Gia Hà Nội\n\n7.Thời gian làm việc:\n\nTừ thứ 2 – thứ 6 (sáng 8h30 -11h30, chiều 13h30-16h30) trừ ngày nghỉ lễ\n\n8\\. Liên hệ: • Phone: [0243 754 9867](tel:0243%20754%209867) / 0985 642 702","slug":"post-6"},{"frontmatter":{"title":"DIY Paper Diamond Tutorial with HUNGRY HEART","description":"meta description","date":"2022-08-12T00:00:00.000Z","image":"/images/posts/04.jpg","categories":["art"],"authors":["Khanh Duy Le"],"tags":["diy","toy"],"draft":false},"content":"\nNemo vel ad consectetur namut rutrum ex, venenatis sollicitudin urna. Aliquam erat volutpat. Integer eu ipsum sem. Ut bibendum lacus vestibulum maximus suscipit. Quisque vitae nibh iaculis neque blandit euismod.\n\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo vel ad consectetur ut aperiam. Itaque eligendi natus aperiam? Excepturi repellendus consequatur quibusdam optio expedita praesentium est adipisci dolorem ut eius!\n\n## Creative Design\n\nNam ut rutrum ex, venenatis sollicitudin urna. Aliquam erat volutpat. Integer eu ipsum sem. Ut bibendum lacus vestibulum maximus suscipit. Quisque vitae nibh iaculis neque blandit euismod.\n\n> Lorem ipsum dolor sit amet consectetur adipisicing elit. Nemo vel ad consectetur ut aperiam. Itaque eligendi natus aperiam? Excepturi repellendus consequatur quibusdam optio expedita praesentium est adipisci dolorem ut eius!\n\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo vel ad consectetur ut aperiam. Itaque eligendi natus aperiam? Excepturi repellendus consequatur quibusdam optio expedita praesentium est adipisci dolorem ut eius!\n","slug":"post-7"},{"frontmatter":{"title":"React Libraries for 2024","description":"Discover the essential React libraries for 2024! Navigate the vast ecosystem effortlessly with this curated list. Empower your React projects with these powerful tools for seamless development of large-scale applications ...","date":"2024-07-28T00:00:00.000Z","image":"/images/posts/04.jpg","categories":["React"],"authors":["Khanh Duy Le"],"tags":["diy","toy"],"draft":false},"content":"\n<Sponsorship />\n\nReact has been around for a while. Since then, a well-rounded yet overwhelming ecosystem of libraries evolved around the component driven library. Developers coming from other programming languages or libraries/frameworks often have a hard time figuring out **all the libraries** for creating web applications with React.\n\nAt its core, React enables one to create component-driven user interfaces with [function components](/react-function-component/). It comes with built-in solutions though, for instance, [React Hooks](/react-hooks/) for local state, side-effects, and performance optimizations. But after all, you are only dealing with functions (components and hooks) to create a UI here.\n\n<ReadMore label=\"React Trends\" link=\"/react-trends/\" />\n\nLet's dive into the libraries that you could use for your next React application.\n\n# Table of Contents\n\n<TableOfContents {...props} />\n\n# Starting a new React Project\n\nThe first question that comes to mind for a React beginner: how to set up a React project. There are many tools to choose from. The most popular choice in the React community is [Vite](https://vitejs.dev/) which allows you to create projects with various library (e.g. React) + opt-in TypeScript combinations. It comes with [incredible performance](https://twitter.com/rwieruch/status/1491093471490412547).\n\n<ReadMore label=\"Learn more about websites and web applications\" link=\"/web-applications/\" />\n\nIf you are already familiar with React, you can choose one of its most popular (meta) frameworks as alternative to Vite: [Next.js](https://nextjs.org/) which builds up on top of React, hence you should know about [React's fundamentals](https://www.roadtoreact.com/). A popular alternative in this arena is [Remix](https://remix.run/).\n\n<ReadMore label=\"How to learn React as a Library or Framework\" link=\"/learning-react/\" />\n\nWhile Next.js has been initially used for server-side rendering (web applications), it can be used for static site generation (websites) next to other rendering patterns too. The most recent addition to Next.js are React Server Components which contribute since 2023 to a big paradigm shift by moving React components from the client to the server.\n\nIf you are looking for a framework with the best performance in mind for static content, you need to check out [Astro](https://astro.build/) which is framework agnostic and therefore can be used with React. It ships only HTML and CSS to the browser even though a framework like React is used for creating the components. Only if these components become interactive, the necessary JavaScript is requested by the client.\n\n<ReadMore label=\"How to start a React project\" link=\"/react-starter/\" />\n\nIf you just want to understand how tools like Vite work, try to [set up a React project](/minimal-react-webpack-babel-setup/) yourself. You will start with a bare bones HTML with JavaScript project and add React with its supportive tools (e.g. Webpack, Babel) yourself. It's not something you will have to deal with in your day to day work, especially since Vite became the successor of Webpack, but it's a great learning experience to get to know the underlying tooling.\n\nIf you are a React veteran and want to try something new, check out [Nitro](https://nitro.unjs.io/) or [Waku](https://github.com/dai-shi/waku). The latter is from creator of Zustand and comes with support for React Server Components.\n\n**Recommendations:**\n\n- Vite for client-side rendered React applications\n- Next server-side rendered React applications\n- Astro for static-side generated React applications\n- optional learning experience: [create a React project from scratch](/minimal-react-webpack-babel-setup/)\n\n# Package Manager for React\n\nThe most widely used package manager to install libraries (read: dependencies, node packages) in the JavaScript ecosystem (and therefore React) is [npm](https://www.npmjs.com/), because it comes with every Node.js installation. However, yarn [yarn](https://yarnpkg.com/) and [pnpm](https://pnpm.io/) are great alternatives. Especially the latter comes with a greater performance boost.\n\n<ReadMore label=\"Mac Setup for Web Development\" link=\"/mac-setup-web-development/\" />\n\nIf you happen to create multiple React applications which depend on each other or which share a common set of custom UI components, you may want to check out the concept of a monorepo. All previously mentioned package managers allow you to create monorepos by using their in-house workspaces feature, however, I had the best developer experience using yarn or pnpm. In combination with monorepo pipeline tools such as [Turborepo](https://turborepo.org/), the monorepo experience becomes perfect.\n\n<ReadMore label=\"Monorepo Setup\" link=\"/javascript-monorepos/\" />\n\n**Recommendations:**\n\n- choose one package manager and stick to it\n  - default and most widely used -> npm\n  - increased performance but fairly new and not as popular -> pnpm\n- if a monorepo is needed, check out Turborepo (see tutorial)\n\n# React State Management\n\nReact comes with two built-in hooks to manage local state: [useState](/react-usestate-hook) and [useReducer](/react-usereducer-hook/). If state needs to be managed globally, one can opt-in [React's built-in useContext Hook](/react-usecontext-hook/) to tunnel props from top-level components to components below them without using [props](/react-pass-props-to-component/) and therefore avoiding the problem of props drilling.\n\n<ReadMore label=\"Learn when to use useState and useReducer\" link=\"/react-usereducer-vs-usestate/\" />\n\nAll three React hooks enable developers to implement powerful state management in React which is either co-located in components by using React's useState/useReducer Hooks or globally managed by combining them with React's useContext Hook.\n\n<ReadMore label=\"Learn how to combine useState/useReducer with useContext\" link=\"/react-state-usereducer-usestate-usecontext/\" />\n\nIf you find yourself using React's Context too often for shared/global state, you should definitely check out [Zustand](https://github.com/pmndrs/zustand). It allows you to manage global application state which can be read and modified by any React component that is connected to its store(s).\n\n<Divider />\n\nEven though I'd say Zustand becomes the de facto standard in the community, once a state management library is needed, you may not get around Redux -- which is still the most popular state management library out there. I haven't used it personally in my last freelance projects over the last years, because I like Zustand for its simplicity, however, you will find plenty of older React applications which come with Redux.\n\n<ReadMore label=\"Redux Tutorial (without Redux Toolkit)\" link=\"/react-redux-tutorial/\" />\n\nIf you happen to use Redux, you should definitely check out [Redux Toolkit](https://redux-toolkit.js.org/) as well. If you are into state machines, check out [XState](https://github.com/statelyai/xstate) or [Zag](https://github.com/chakra-ui/zag). As alternatives, if you need a global store but do not like Zustand or Redux, check other popular local state management solutions like [Jotai](https://github.com/pmndrs/jotai), [Recoil](https://github.com/facebookexperimental/Recoil), or [Nano Stores](https://github.com/nanostores/nanostores).\n\n**Recommendations:**\n\n- useState/useReducer for co-located or shared state (see tutorial)\n- opt-in useContext for enabling _little_ global state (see tutorial)\n- Zustand (or an alternative) for _lots of_ global state\n\n# React Data Fetching\n\nReact's built-in hooks are great for UI state, but when it comes to state management (read: caching) for remote data (and therefore data fetching), I would recommend using a dedicated data fetching library such as [TanStack Query](https://tanstack.com/query) (formerly React Query).\n\nWhile TanStack Query itself is not seen as a state management library, because it is primarily used to fetch your remote data from APIs, it takes care of all the state management (e.g. caching, optimistic updates) of this remote data for you.\n\n<ReadMore label=\"Learn how TanStack Query works under the hood\" link=\"/react-hooks-fetch-data/\" />\n\nTanStack Query was designed for consuming [REST APIs](/node-express-server-rest-api/). However, these days it supports [GraphQL](https://www.roadtographql.com/) too. However, if you are looking for a more dedicated GraphQL library for your React frontend, check out either [Apollo Client](https://www.apollographql.com/docs/react/) (popular), [urql](https://formidable.com/open-source/urql/) (lightweight), or [Relay](https://github.com/facebook/relay) (by Facebook).\n\n<ReadMore label=\"Everything about State in React for Local and Remote Data\" link=\"/react-state/\" />\n\nIf you are already using Redux and want to add data fetching with integrated state management in Redux, instead of adding TanStack Query, you may want to check out [RTK Query](https://redux-toolkit.js.org/rtk-query/overview) which integrates data fetching neatly into Redux.\n\nLast but not least, if you control the frontend and the backend (both TypeScript), check out [tRPC](https://trpc.io/) for end-to-end type safe APIs. I have been using it for the last year and it is a tremendous productivity boost and DX. It can be combined with TanStack Query for all the niceties regarding data fetching while still being able to call your backend from your frontend by using typed functions.\n\n<ReadMore label=\"Create your first tRPC application with E2E type safety\" link=\"/react-trpc/\" />\n\n**Recommendations:**\n\n- TanStack Query (REST APIs or GraphQL APIs)\n  - combined with axios or [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)\n- Apollo Client (GraphQL APIs)\n- tRPC for tightly coupled client-server architectures\n- optional learning experience: [learn how TanStack Query works](/react-hooks-fetch-data/)\n\n# Routing with React Router\n\nIf you are using a React framework like Next.js, routing is already taken care of for you. However, if you are using React without a framework and only for client-side rendering (e.g. Vite without SSR), the most powerful and popular routing library out there is [React Router](https://reactrouter.com/). A new alternative with full TypeScript support in mind is [TanStack Router](https://tanstack.com/router).\n\n<ReadMore label=\"Learn to use React Router\" link=\"/react-router/\" />\n\nIf you are using client-side routing in React with React Router, it's not much work introducing code splitting on a route level. If you happen to introduce this kind of optimization, you could substitute `React.lazy()` with `@loadable/component`.\n\n<ReadMore label=\"Learn Lazy Loading with React Router\" link=\"/react-router-lazy-loading/\" />\n\nBefore you introduce a router in your React project, when you are just about to learn React, you can give [React's conditional rendering](/conditional-rendering-react/) a shot first. It is not a replacement for routing, but gives you a glimpse on how replacing components on a page level works.\n\n**Recommendations:**\n\n- most used: React Router\n- trending: TanStack Router\n  - primarily for its first-class TS support\n\n# CSS Styling in React\n\nThere are many options and even more opinions about styling/CSS in React out there, so putting everything in one section here does not suffice. If you want to get deeper into this topic and get to know all the options, check out the following guide.\n\n<ReadMore label=\"React CSS Styling (Comprehensive Tutorial)\" link=\"/react-css-styling/\" />\n\nAs a React beginner, it is okay to start with inline styles and bare bones CSS by using a style object in JSX. It should be rarely used for actual applications though:\n\n```javascript\nconst Headline = ({ title }) => <h1 style={{ color: \"blue\" }}>{title}</h1>;\n```\n\nWhereas inline style can be used to add style dynamically with JavaScript in React's JSX, an external CSS file could hold all the remaining style for your React application:\n\n```javascript{1,4}\nimport './Headline.css';\n\nconst Headline = ({ title }) =>\n  <h1 className=\"headline\" style={{ color: 'blue' }}>\n    {title}\n  </h1>\n```\n\nOnce your application grows in size, there are other styling approaches to check out.\n\n<Divider />\n\nFirst, I would recommend you to have a look into CSS Modules as one of many _CSS-in-CSS_ solutions. CSS Modules give you a way to encapsulate your CSS into component co-located modules. This way, styles don't leak accidentally into other components:\n\n```javascript{1,4}\nimport styles from './style.module.css';\n\nconst Headline = ({ title }) =>\n  <h1 className={styles.headline}>\n    {title}\n  </h1>\n```\n\nSecond, I want to show (not recommend anymore) you Styled Components as one of many _CSS-in-JS_ solutions for React. This approach is brought to you by a library called [styled-components](/react-styled-components/) (or alternatives such as [emotion](https://emotion.sh/)) which co-locates styling created with JavaScript next to your React components in the same file or a co-located file:\n\n```javascript\nimport styled from \"styled-components\";\n\nconst BlueHeadline = styled.h1`\n  color: blue;\n`;\n\nconst Headline = ({ title }) => <BlueHeadline>{title}</BlueHeadline>;\n```\n\n<ReadMore label=\"Best Practices for Styled Components\" link=\"/styled-components/\" />\n\nAnd third, I want to recommend [Tailwind CSS](https://tailwindcss.com/) as the most popular _Utility-First-CSS_ solution. It comes with pre-defined CSS classes. This makes you more efficient as a developer and streamlines the design system of your React application, but comes with the tradeoff of getting to know all the classes and verbose inlining of many CSS classes:\n\n```javascript\nconst Headline = ({ title }) => <h1 className=\"text-blue-700\">{title}</h1>;\n```\n\nWhether you choose CSS-in-CSS or Utility-First-CSS is up to you. The trend goes towards Utility-First-CSS with Tailwind CSS. CSS-in-JS solutions are not as popular anymore because of their problems with server-side environments. One last hint: If you want to apply a className conditionally in React, use a utility library like [clsx](https://github.com/lukeed/clsx).\n\n**Recommendations:**\n\n- Utility-First-CSS (most popular)\n  - e.g. Tailwind CSS\n- CSS-in-CSS\n  - e.g. CSS Modules\n- CSS-in-JS\n  - e.g. [StyleX](https://stylexjs.com/) by Facebook (compiles to utility-first CSS)\n  - e.g. Styled Components (personally I'd not recommended runtime CSS-in-JS anymore due to performance and other problems in server-side environments)\n- [CSS-in-TS](https://github.com/andreipfeiffer/css-in-js) (which support TypeScript and server-side-rendering)\n\n# React UI Libraries\n\nAs a beginner, it is a great and recommended learning experience to build reusable components from scratch. Whether it is a [dropdown](/react-dropdown/), a [select](/react-select/), a [radio button](/react-radio-button/), or a [checkbox](/react-checkbox/), you should know how to create these UI components yourself eventually.\n\nHowever, if you don't have the resources to come up with all the components yourself, you want to use a UI library which gives you access to lots of pre-built components which share the same design system, functionalities, and rules for accessibility:\n\n- [Material UI (MUI)](https://material-ui.com/) (still most wanted in freelance projects)\n- [Mantine UI](https://mantine.dev/) (most popular 2022)\n- [Chakra UI](https://chakra-ui.com/) (most popular 2021)\n- [NextUI](https://nextui.org/) (based on React Aria)\n- [Park UI](https://park-ui.com/) (based on Ark UI)\n\nThe trend moves towards headless UI libraries though. They come without styling, but with all the functionalities and accessibilities that a modern component library needs. Most of the time they are combined with a Utility-First-CSS solution like Tailwind:\n\n- [shadcn/ui](https://ui.shadcn.com/) (most popular 2023)\n- [Radix](https://www.radix-ui.com/)\n- [React Aria](https://react-spectrum.adobe.com/react-aria/)\n- [Catalyst](https://tailwindcss.com/blog/introducing-catalyst)\n- [Daisy UI](https://daisyui.com/)\n- [Headless UI](https://headlessui.com/)\n- [Tailwind UI](https://www.tailwindui.com/) (not free)\n- [Ark UI](https://ark-ui.com/) (from the makers of Chakra UI)\n\nPerhaps more out of fashion compared to the other UI libraries:\n\n- [Ant Design](https://ant.design/)\n- [Semantic UI](https://react.semantic-ui.com/)\n- [React Bootstrap](https://react-bootstrap.github.io/)\n- [Reactstrap](https://reactstrap.github.io/?path=/story/home-installation--page)\n\nEven though all of these UI libraries come with in-house components, they cannot make each component as powerful as libraries which focus only on one UI component. For example, [react-table-library](https://react-table-library.com/) allows you to create powerful table components in React while also offering you themes (e.g. Material UI) for combining it with UI libraries.\n\n# React Animation Libraries\n\nAny animation in a web application starts with CSS. Eventually you will notice that CSS animations aren't enough for your needs. Usually developers check out [React Transition Group](https://reactcommunity.org/react-transition-group/) then, which gives them the possibility to perform animations with React components. Other well known animation libraries for React are:\n\n- [Framer Motion](https://www.framer.com/motion/) (most recommended)\n- [react-spring](https://github.com/react-spring/react-spring)\n- [react-motion](https://github.com/chenglou/react-motion)\n- [react-move](https://github.com/sghall/react-move)\n\n# Visualization and Chart Libraries in React\n\nIf you really want to build charts from the ground up yourself, there is no way around [D3](https://d3js.org/). It's a low level visualization library that gives you everything you need to create amazing charts. However, learning D3 is a whole other adventure, thus many developers just pick a React charting library which does everything in exchange for flexibility. Popular solutions are:\n\n- [Recharts](http://recharts.org) (personal recommendation)\n  - off the shelf charts\n  - great composability\n  - optional customization due to opt-in composability\n- [visx](https://github.com/airbnb/visx)\n  - leaning more towards low-level D3 than high-level abstraction\n  - steeper learning curve\n- more off the shelf charts, more difficult to customize\n  - [Victory](https://formidable.com/open-source/victory/)\n  - [nivo](https://nivo.rocks/)\n  - [react-chartjs](https://github.com/reactchartjs/react-chartjs-2)\n\n# Form Libraries in React\n\nThe most popular library for forms in React is [React Hook Form](https://react-hook-form.com/). It comes with everything needed: validation (most popular integrations is [zod](https://github.com/colinhacks/zod)), form submission, form state management. As alternative there are [Formik](https://github.com/jaredpalmer/formik) and [React Final Form](https://final-form.org/react). If you are using a React UI library, check out how they integrate with one of these libraries.\n\n<ReadMore label=\"How to use Forms in React\" link=\"/react-form/\" />\n\n**Recommendations:**\n\n- React Hook Form\n  - with zod integration for validation\n\n# React Type Checking\n\nReact comes with an in-house props validation called [PropTypes](https://facebook.github.io/react/docs/typechecking-with-proptypes.html). By using PropTypes, you are able to define the props for your React components. Whenever a prop with a wrong type is passed to the component, you will get an error message:\n\n```javascript\nimport PropTypes from \"prop-types\";\n\nconst List = ({ list }) => (\n  <div>\n    {list.map((item) => (\n      <div key={item.id}>{item.title}</div>\n    ))}\n  </div>\n);\n\nList.propTypes = {\n  list: PropTypes.array.isRequired,\n};\n```\n\nHowever, PropTypes are not included in React anymore. I would not recommend using them, however, for the sake of historical reason I still keep them around here.\n\nThe industry standard is using TypeScript in React applications. These days, there are rarely new React projects started without TypeScript, so you should get into with it too:\n\n```typescript\ntype Item = {\n  id: string;\n  title: string;\n};\n\ntype ListProps = {\n  list: Item[];\n};\n\nconst List = ({ list }: ListProps) => (\n  <div>\n    {list.map((item) => (\n      <div key={item.id}>{item.title}</div>\n    ))}\n  </div>\n);\n```\n\n[TypeScript](https://www.typescriptlang.org/) is the way to go these days. If you want to go beyond TypeScript for typed form validation, API validations (e.g. when using tRPC) and more, check out [Zod](https://github.com/colinhacks/zod).\n\n**Recommendations:**\n\n- if typed JavaScript is wanted, use TypeScript\n\n# Code Structure in React\n\nIf you want to embrace a unified and common sense code style, use [ESLint](https://eslint.org/) in your React project. A linter such as ESLint enforces a particular code style. For example, you can make it a requirement with ESLint to follow a popular style guide (e.g. [Airbnb Style Guide](https://www.npmjs.com/package/eslint-config-airbnb)). Also integrate [ESLint in your IDE/editor](/vscode-eslint/) and it will point you to every mistake.\n\n<ReadMore label=\"React File/Folder Structure (Comprehensive Tutorial)\" link=\"/react-folder-structure/\" />\n\nIf you want to embrace a unified code format, use [Prettier](https://github.com/prettier/prettier) in your React project. It is an opinionated code formatter with only a handful of opt-in configurations. You can [integrate it in your editor or IDE](/how-to-use-prettier-vscode/) so that it formats your code every time you save a file. Prettier doesn't replace ESLint though, but it [integrates nicely](/prettier-eslint/) with it.\n\nMaybe a rising star in 2024 will be [Biome](https://biomejs.dev/) (formerly Rome). ESLint and Prettier are not the most favorite utilities when it comes to their setup and especially interplay. But they are necessary in every web developer's daily work. Biome wants to be an alternative to Prettier and ESLint by providing a fast (Rust based) and all-in-one toolchain.\n\n**Recommendations:**\n\n- ESLint + Prettier\n- give Biome a chance\n\n# React Authentication\n\nIn a React application, you may want to introduce authentication with functionalities such as sign up, sign in, and sign out. Other features like password reset and password change features are often needed as well. These features go far beyond React, because a backend application manages these things for you.\n\n<ReadMore label=\"How to prepare for authentication with React Router\" link=\"/react-router-authentication/\" />\n\nThe best learning experience would be implementing a backend application with authentication (e.g. [GraphQL backend](/graphql-apollo-server-tutorial/)) yourself. However, since authentication comes with lots of security risks and nitty gritty details not everyone knows about, I advice to use one of many authentication/backend-as-a-service solutions which are out there:\n\n- [Lucia](https://github.com/lucia-auth/lucia)\n  - very interesting open source project\n  - makes you independent from any third-party service (lock-in)\n- [Supabase Auth](https://supabase.com/docs/guides/auth/overview)\n- [Clerk](https://clerk.com/)\n- [AuthKit](https://www.authkit.com/)\n- [NextAuth](https://next-auth.js.org/)\n- [Firebase Auth](/complete-firebase-authentication-react-tutorial/)\n- [Auth0](https://auth0.com/)\n- [AWS Cognito](https://aws.amazon.com/cognito/)\n\n# React Backend\n\nSince there is a strong trend moving React to the server, the most natural habitat for a React project would be a meta framework like Next.js, Astro, or Remix.\n\nIf you can't use a full-stack framework due to various reasons (while still being able to use a JS/TS), you have to check out [tRPC](https://trpc.io/) or [Hono](https://hono.dev/). Honorable mention goes to the old school but must popular Node backend [Express](https://expressjs.com/). Other alternatives are [Fasitfy](https://fastify.dev/) or [Nest](https://nestjs.com/).\n\n# React Database\n\nNot tied to React, but since full-stack React applications are getting popular these days, React is closer than ever to the database layer. While developing any Next.js application, you will most likely deal with a database ORM. The most popular ORM choice these days is [Prisma](https://www.prisma.io/?via=rwieruch). A trending alternative is [Drizzle ORM](https://orm.drizzle.team/). More alternatives are [Kysely](https://kysely.dev/) and [database-js](https://github.com/planetscale/database-js) (only PlanetScale).\n\nWhen it comes to choosing a database, Supabase (or Firebase) are valid database providers. Supabase with its PostgreSQL can be self-hosted or used as a paid service. Popular alternatives which offer serverless databases are [PlanetScale](https://planetscale.com/) (personal recommendation), [Neon](https://neon.tech/), and [Xata](https://xata.io/).\n\n<ReadMore label=\"Web Development Trends\" link=\"/web-development-trends/\" />\n\n# React Hosting\n\nYou can deploy and host a React application like any other web application. If you want to have full control, choose something like [Digital Ocean](https://m.do.co/c/fb27c90322f3). If you want to have someone taking care of everything, [Netlify](https://www.netlify.com/) or [Vercel](https://vercel.com/) (especially for Next.js) are popular solutions.\n\nIf you are already using a third-party backend as a service like Firebase/Supabase, you can check whether they offer hosting as well. Other popular hosting providers are [Render](https://render.com/), [Fly.io](https://fly.io/), [Railway](https://railway.app/), or directly at AWS/Azure/Google Cloud/Hetzner.\n\n# Testing in React\n\nIf you want to get a deep dive about testing in React, read this: [How to test components in React](/react-testing-tutorial/). The gist: The backbone of testing a React application is a test framework like [Jest](https://github.com/facebook/jest). It gives you test runner, assertion library and spying, mocking, stubbing functionalities. Everything that's needed from a comprehensive test framework. If you are a fan of Vite, you should check out [Vitest](https://vitest.dev/) as viable Jest alternative though.\n\nAt the minimum, you can render React components in your testing framework with [react-test-renderer](https://www.npmjs.com/package/react-test-renderer). This is already sufficient to perform so-called [Snapshot Tests with Jest](/react-testing-jest/) or Vitest. A snapshot test works the following way: Once you run your tests, a snapshot of your rendered DOM elements of the React component is created. When you run your tests again at some point in time, another snapshot is created which is used as diff for the previous snapshot. If the diff is not identical, the test framework will complain and you either have to accept the snapshot or adjust your component.\n\nEventually you will find yourself using the popular [React Testing Library (RTL)](/react-testing-library/), which is used within your testing framework's environment, as a comprehensive testing library for React. RTL makes it possible to render your components and to simulate events on HTML elements. Afterward, your test framework is used for the assertions.\n\nIf you are looking for a testing tool for React end-to-end (E2E) tests, [Playwright](https://playwright.dev/) and [Cypress](/react-testing-cypress/) are the most popular choices.\n\n**Recommendations:**\n\n- Unit/Integration: Vitest + React Testing Library (most popular)\n- Snapshot Tests: Vitest\n- E2E Tests: Playwright or Cypress\n\n# React and Immutable Data Structures\n\nVanilla JavaScript gives you plenty of built-in tools to handle data structures as if they are immutable. However, if you and your team feel the need to enforce immutable data structures, the most popular choice is [Immer](https://github.com/immerjs/immer).\n\n# React Internationalization\n\nWhen it comes to [internationalization i18n for your React application](/react-internationalization/), you need to think not only about translations, but also about pluralizations, formattings for dates and currencies, and a handful of other things. These are the most popular libraries for dealing with it:\n\n- [FormatJS](https://github.com/formatjs/formatjs)\n- [react-i18next](https://github.com/i18next/react-i18next)\n- [Lingui](https://lingui.dev/)\n\n# Rich Text Editor in React\n\nWhen it comes to Rich Text Editors in React, I can only think of the following:\n\n- [Plate](https://platejs.org/)\n- [Lexical](https://github.com/facebook/lexical)\n- [Slate.js](https://www.slatejs.org/)\n\n# Payments in React\n\nThe most common payment providers are Stripe and PayPal. Both can be neatly integrated into React. This is a [working Stripe Checkout with React integration](https://github.com/rwieruch/react-express-stripe).\n\n- [PayPal](https://developer.paypal.com/docs/checkout/)\n- Stripe\n  - [React Stripe Elements](https://github.com/stripe/react-stripe-js)\n  - [Stripe Checkout](https://stripe.com/docs/payments/checkout)\n\n# Time in React\n\nIf your React application deals heavily with dates, times, and timezones, you could introduce a library which manages these things for you. These are your options:\n\n- [date-fns](https://github.com/date-fns/date-fns)\n- [Day.js](https://github.com/iamkun/dayjs)\n- [Luxon](https://github.com/moment/luxon/)\n\n# React Desktop Applications\n\n[Electron](https://www.electronjs.org/) and [Tauri](https://github.com/tauri-apps/tauri) are the go to frameworks for cross-platform desktop applications.\n\n# File Upload in React\n\n- [react-dropzone](https://react-dropzone.js.org/)\n\n# Mails in React\n\n- [react-email](https://react.email/) (personal recommendation)\n- [Mailing](https://www.mailing.run/)\n- [mjml](https://mjml.io/)\n\n# Drag and Drop\n\nPersonally I have used [the successor of react-beautiful-dnd](https://github.com/hello-pangea/dnd) and cannot say anything negative about it. A popular alternative which offers way more flexibility and options, but comes with the cost of a steeper learning curve, is [dnd kit](https://dndkit.com/). Another alternative in the space is [react-dnd](https://github.com/react-dnd/react-dnd).\n\n# Mobile Development with React\n\nThe go-to solution for bringing React from the web to mobile is still [React Native](https://facebook.github.io/react-native/). The most popular framework for creating React Native applications is [Expo](/react-native-expo/). If you need unified components across web and mobile, you want to check out [Tamagui](https://tamagui.dev/).\n\n<ReadMore label=\"Learn Navigation in React Native\" link=\"/react-native-navigation/\" />\n\n# React VR/AR\n\nIt's possible to dive into virtual reality or augmented reality with React. To be honest, I haven't used any of these libraries and most are early stage (experimental), but they are the ones I know from the top of my head when it comes to AR/VR in React:\n\n- [react-three-fiber](https://github.com/pmndrs/react-three-fiber) (popular 3d library, however, I have seen VR examples too)\n- [react-360](https://facebook.github.io/react-360/)\n- [aframe-react](https://github.com/supermedium/aframe-react)\n\n# Design Prototyping for React\n\nIf you are coming from a UI/UX background, you may want to use a tool for fast prototyping for new React components, layouts, or UI/UX concepts. Personally I use [Figma](https://www.figma.com/). For rough yet lightweight sketches, I like to use [Excalidraw](https://excalidraw.com/), others prefer [tldraw](https://www.tldraw.com/).\n\n# React Component Documentation\n\nIf you are in charge of writing the documentation for your components, there are various neat React documentation tools out there. I've used [Storybook](https://storybook.js.org/) in many projects and have a neutral opinion about it. I've heard good things about these other solutions too:\n\n- [Docusaurus](https://github.com/facebook/docusaurus)\n- [Docz](https://github.com/doczjs/docz)\n- [Styleguidist](https://github.com/styleguidist/react-styleguidist)\n- [React Cosmos](https://reactcosmos.org/)\n","slug":"post-8"}]