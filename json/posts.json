[{"frontmatter":{"title":"Website analytics platform for bloggers and content creators","description":"Here's a look at why we created Plausible Analytics as a great Google Analytics alternative for content creators and their personal websites and blogs.","date":"2023-04-04T00:00:00.000Z","image":"/images/posts/01.jpg","categories":["development"],"authors":["Mark Dinn"],"tags":["Plausible","Google Analytics"],"draft":false},"content":"\r\nMany people create content on their personal websites and blogs. There are many motivations behind this. Some use it like a diary, some as a hobby, or as a way to connect to other people, as a way to build an audience, make money and even improve their career opportunities. \r\n\r\nFor some of these content creators, external recognition is not that important. They write what they want, about things they are interested in and they publish whatever they please. The fun is in the writing and the creative process itself.\r\n\r\nOthers like to understand the impact that their efforts have on the world, which posts bring in the readers, what topics people seem to enjoy the most and even how people end up discovering their content in the first place.\r\n\r\n![Website analytics for bloggers and content creators](https://storage.googleapis.com/support-kms-prod/Z2xIkRrq4V2vmeRtcDkeYRozBSJmaHRzuxRI \"Website analytics for bloggers and content creators\")\r\n\r\n## Web analytics give you a strong signal\r\n\r\nThis helps motivate them to put even more effort, publish more of the content that people enjoy the most and create a better website experience in general.\r\n\r\nAnd this is where website analytics come into the picture. Web analytics give website owners and bloggers a strong signal on what they have achieved, what worked well and what not so well. This helps them improve and better organize their future efforts. \r\n\r\nGoogle Analytics is the obvious and the default choice for most websites. Even though it is a very useful and powerful tool used on the majority of websites on the web, it [brings several issues](https://plausible.io/blog/remove-google-analytics) that distract site owners from what they enjoy doing the most. \r\n\r\nHere's a look at why we created Plausible Analytics as a great [Google Analytics alternative](https://plausible.io/vs-google-analytics) for content creators and their personal websites and blogs.\r\n\r\n## Google Analytics is complicated to use and understand\r\n\r\nGoogle Analytics collects so much data from website visitors that it can showcase more than 125 different reports and almost 300 individual metrics. You as a site owner will rarely have a need for more than a handful of these. This makes Google Analytics an overkill for the majority of bloggers.\r\n\r\nMany try to simplify Google Analytics by creating custom reports and custom dashboards. Some even take Google Analytics training courses in order to learn how to use it, how to understand the different metrics and extract actionable insights from them.\r\n\r\nIf you just want to publish content and interact with people, learning about analytics is not something you put on top of your priority list. So you end up ignoring Google Analytics. You keep it installed on your site and it keeps tracking your visitors but you don't really get much value from it.\r\n\r\nPlausible Analytics is built with [simplicity in mind](https://plausible.io/simple-web-analytics). Anyone can understand all the metrics we present at a glance and without having any training or prior analytics experience. Everything you need to know is on one page.\r\n\r\nYou can get an overview of all the most actionable metrics in one minute and get on with tasks that you enjoy more such as creating new content or engaging with your audience.\r\n\r\n## Google Analytics requires a privacy policy, cookie prompt and user consent\r\n\r\nThere are several requirements for using Google Analytics. Some from Google's side and others from the different privacy regulations.\r\n\r\nGoogle for instance [requires](https://marketingplatform.google.com/about/analytics/terms/us/) you to have a privacy policy with details on your usage of Google Analytics. \r\n\r\n> “You must post a Privacy Policy and that Privacy Policy must provide notice of Your use of cookies, identifiers for mobile devices or similar technology used to collect data. You must disclose the use of Google Analytics, and how it collects and processes data. You will use commercially reasonable efforts to ensure that a User is provided with clear and comprehensive information about, and consents to, the storing and accessing of cookies or other information on the User’s device where such activity occurs in connection with the Service and where providing such information and obtaining such consent is required by law.”\r\n\r\nOn top of this, Google Analytics places [multiple cookies](https://developers.google.com/analytics/devguides/collection/analyticsjs/cookie-usage) on the machines of your visitors which means that you need to ask for cookie consent from your visitors too.\r\n\r\nThese are things that many site owners and bloggers simply don't want to nor have the time or capacity to deal with. And the value that Google Analytics provides may not be worth it in terms of what it takes to have it running with regards to dealing with privacy policy and cookie consent.\r\n\r\nPlausible Analytics is compatible with the different privacy regulations such as GDPR, CCPA and PECR out of the box. [We don't use cookies](https://plausible.io/data-policy) and we don't collect any personal data from your visitors either. This means that you don't need to have a privacy policy regarding Plausible Analytics and you don't need to have a cookie banner nor ask to get consent from your visitors.\r\n\r\nYou keep your site simple, clean and optimized for your visitors. No need to put any time and effort into legal aspects. You can focus on the more creative side of things.\r\n\r\n## Google Analytics slows down your site and worsens the visitor experience\r\n\r\nGoogle Analytics is a bloated script that collects a lot of unnecessary data and it's not useful for the majority of site owners. This can lead to your site having slower loading times. It is common that the different speed tests including Google's own PageSpeed Insights flag Google Analytics as one of the elements that slow down a site.\r\n\r\nThe recommended way to start tracking your website using Google Analytics is to install the Global Site Tag (gtag.js) tracking code on all of your pages. It weighs 28 KB and it downloads another file called the Google Analytics tag which adds an additional 17.7 KB to your page size. These two tracking scripts combined add 45.7 KB of page weight to each and every page load.\r\n\r\nEvery KB can make a difference if you want to optimize for speed. Plausible Analytics script [weighs less than 1 KB](https://plausible.io/lightweight-web-analytics). That’s more than 45 times smaller than the Google Analytics Global Site Tag. Your site will keep loading fast and your visitors will have a smooth experience. \r\n\r\n## Google Analytics is blocked by many web users\r\n\r\nGoogle Analytics is the most widely used tracking script on the web. This makes it a big target. Browsers such as Brave and Firefox block it, so do the different ad-blocking extensions such as the uBlock Origin. \r\n\r\nThese are used by millions of web users who won't be counted in your website statistics. It's not uncommon to see 40% or even more of the audience on a tech website blocking Google Analytics.\r\n\r\nPlausible Analytics is a new player on this market and it's privacy-friendly by default, so it doesn't see the same level of blockage. We also have a proxy that allows you to run our script as a [first party connection from your domain name](https://plausible.io/docs/proxy/introduction). You may very well see more accurate (and higher) visitor numbers.\r\n","slug":"post-1"},{"frontmatter":{"title":"Umami - The Better Google Analytics Alternative","description":"Find out why Umami is the best GA alternative.","date":"2024-04-30T00:00:00.000Z","image":"/images/posts/02.jpg","categories":["development"],"authors":["John Doe"],"tags":["Umami","Google Analytics"],"draft":false},"content":"\r\nBoth businesses and personal users need to understand their website data to gain insights into how their customers, users, and visitors engage with their content. Google Analytics provides these insights into website traffic, but its practices raise concerns about user privacy and data protection. Like most Google products, Google Analytics is free because Google collects all sorts of data and then uses it to make money in its other products, like Google Ads.\r\n\r\nThis blog post explores how Google Analytics works, the privacy implications regarding the data it collects and how it uses it, and why Umami is a suitable privacy-first alternative.\r\n\r\n# How Google Analytics Works\r\n\r\nTo use Google Analytics, website owners have to first create an account and then add a tracking code to their website. The tracking code collects user behavior data, including the user's IP address, device, browser, and location. Google Analytics uses cookie-based tracking to monitor users across different sessions and to identify unique users.\r\nWhat Data Does Google Analytics Collect?\r\nGoogle Analytics collects various data about a user's behavior on a website. Such as:\r\n\r\n1. **User location**: Google Analytics can track a user's location based on their IP address. This allows website owners to see where their visitors are coming from and can help them tailor their content to specific regions.\r\n2. **Device type**: Google Analytics can track the user's device (i.e., desktop, iPhone, tablet, etc). This includes information about the user's operating system, browser, and screen size.\r\n3. **User behavior**: Google Analytics tracks what users do on a website, such as page visits, time on site, and actions they perform (such as filling out a form, clicking a button, etc.). With specific settings enabled, Google Analytics can also track things like scroll depth.\r\n4. **Referral source**: Google Analytics can track how users find the website, whether through a search engine, social media, clicking a link in an email, a paid advertisement, or another website.\r\n5. **Demographic information**: Google Analytics can provide demographic information about users, such as age, gender, and interests.\r\n\r\nGoogle can also source and combine data from other Google services like Search and YouTube and share it back to Google Analytics. Google states in Data Share Settings sections of the Google Analytics docs that, “Google products & services: When you turn this setting ON, Google can access and analyze data to better understand online behavior and trends, and use this data to improve Google products and services.”\r\n\r\n# How Does Google Analytics Use This Data?\r\n\r\nGoogle Analytics uses the data it collects on website visitors and creates profiles for them, which advertising can use as targeting criteria in their Google Ads campaigns. For example, if a user is identified as being interested in a particular topic (such as networking software), they may be shown ads related to that topic.\r\n\r\nGoogle can bucket users into two categories: Affinity or In-Market. Affinity means the user is generally interested in a topic, and In-Market suggests the user is in the market to make a purchase. Google aggregates your actions online - not just from your website activity on Google Analytics - to create a profile for you. If a user visits a website about a new Honda, gets directions to the Honda dealership in Google Maps, visits websites about auto financing, and watches YouTube videos about Honda reviews, Google will bucket you as someone in the market to purchase a new car.\r\n\r\nAlthough this type of advertising can work because it is based on the user's interests and behavior, it can feel unsavory that Google is tracking everything you're doing and bucketing you into categories. How would you feel if I stood over your shoulder watching and writing down everything you did, everywhere you went, and then used that information to sell something to you? We probably wouldn't be friends.\r\n\r\nThere are concerns about this data regarding user privacy, such as:\r\n\r\n- Users might not know this data is being tracked\r\n- Users should be informed that this data is being collected\r\n- Users should have to give their consent for their data to be used in this way\r\n\r\nAnother concern is that the data collected by Google is only sometimes correct, which can lead to false assumptions about users' behavior.\r\n\r\n# Privacy Implications of Using Google Analytics\r\n\r\nUsing Google Analytics raises questions about user consent and control over their personal information. Many users likely don't know the extent of the data collection and the implications of allowing Google Analytics to track their online activity. This lack of transparency and control over personal data goes against privacy and data protection principles.\r\n\r\nThe potential for data breaches on the information collected by Google Analytics is a concern. Users entrust their browsing behavior and personal details to website owners, who are responsible for safeguarding this data. However, reliance on third-party services like Google Analytics introduces additional security risks that may compromise user privacy.\r\n\r\n# What Can Website Owners Do to Protect User Privacy?\r\n\r\nWebsite owners should prioritize transparency and user consent when implementing tracking tools like Google Analytics. Respecting user privacy and providing clear information about what data is being collected can help build trust and foster a more ethical approach to website analytics.\r\n\r\nOne way to do this is to provide users with a clear and prominent privacy policy that explains what data is collected, why it is collected, and how it is used. Website owners should also give users the option to opt out of data collection if they choose to do so. This typically comes in the form of cookie opt-in/opt-out banners, where users need to click a button to be tracked.\r\n\r\nAnother option is to use an alternative analytics tool that prioritizes user privacy. Privacy-focused website analytics tools, such as Umami, are now commonly available. Umami offers [similar features](/features) to Google Analytics but with a significantly greater focus on user privacy. Umami is a cookie-free website analytics platform that does not require those annoying opt-in cookie banners.\r\n\r\nUmami has two versions: self-hosted and cloud. Both versions allow full data ownership since users can export all their data from Umami anytime. This can provide added security and peace of mind for businesses concerned about data privacy. On the other hand, Google Analytics stores data on Google's servers, which some companies may be uncomfortable with.\r\n\r\nThere are concerns with Google Analytics regarding user privacy and data protection. Website owners should prioritize transparency and user consent when implementing tracking tools like Google Analytics. Respecting user privacy and providing clear information about what data is being collected and how it is being used can help build trust and foster a more ethical approach to website analytics.\r\n\r\nTry [Umami](https://cloud.umami.is/signup?ref=umami-blog) today, which makes it easy to collect, analyze, and understand your web data while maintaining visitor privacy and data ownership.","slug":"post-2"},{"frontmatter":{"title":"Virtual Machine Detection In The Browser","description":"This blog post covered four unique VM detection capabilities that can be performed from Javascript","date":"2022-06-02T00:00:00.000Z","image":"/images/posts/03.jpg","categories":["development"],"authors":["bannedit's musings"],"tags":["VM","Javascript"],"draft":false},"content":"\r\n### Introduction\r\n\r\nVirtual Machine (VM) detection is nothing new. Malware has been doing it for over a decade now. Over time the techniques have advanced as defenders learned new ways of avoiding VM detection.\r\n\r\nA while back a friend and I were working on a project related to exploit delivery via a web application for redteaming purposes. I wanted a way to fingerprint visitors of the site and hash the fingerprint data so I could look for potential repeat visitors. While investigating fingerprinting I stumbled upon something pretty interesting. I was looking at some code that collected information about WebGL capabilities. I quickly realized that some of the fingerprinting information could be useful for VM detection because vendor names were exposed. In this particular instance the string \"VMWare\" was contained within the WebGL information. After some more testing I also discovered that VirtualBox reported the same kind of information.\r\n\r\nOnce I realized it was potentially possible to detect VMs from the browser I started to dig deeper and began searching for other research related to this discovery. I found a pretty well researched academic paper [\\[1\\]](http://yinzhicao.org/TrackingFree/crossbrowsertracking_NDSS17.pdf) related to tracking users across multiple browsers. This gave me some other potential techniques that could be applied to VM detection.\r\n\r\nThe end goal of this research is to have multiple techniques for VM detection. Multiple techniques lead to much more accurate detection. Since some techniques are more false-positive prone than others, a weighting system can be applied to the detection capabilities. This allows us to generate detection confidence scoring. This can help account for inaccuracies of certain detection methods. Given enough testing and data it would then be possible to come up with a reasonable threshold value. If a browser scores above the threshold then it would most likely be within a VM. Alternatively, if the browser scored below the threshold value it could be considered to be running on physical hardware.\r\n\r\n### Techniques\r\n\r\nNow that I have covered some of the background information and history leading up to this blog post we can start to dig into the actual techniques.\r\n\r\nAs mentioned prior in the introduction, WebGL can provide a lot of information about the OpenGL implementation including vendor information. The WEBGL\\_debug\\_renderer\\_info extension [\\[2\\]](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_debug_renderer_info) can be used to query for debug information such as the WebGL vendor and rendered.\r\n\r\n```javascript\r\nvar canvas \\= document.createElement('canvas');\r\nvar gl \\= canvas.getContext('webgl');\r\n\r\nvar debugInfo \\= gl.getExtension('WEBGL\\_debug\\_renderer\\_info');\r\nvar vendor \\= gl.getParameter(debugInfo.UNMASKED\\_VENDOR\\_WEBGL);\r\nvar renderer \\= gl.getParameter(debugInfo.UNMASKED\\_RENDERER\\_WEBGL);\r\n\r\nconsole.log(vendor);\r\nconsole.log(renderer);\r\n```\r\n\r\nAdditionally, extension availability can be queried using the **_getExtension_** method on a WebGL context. I have not fully explored this avenue but it might be possible to detect certain WebGL implementations provided by VMs based on the extensions available. Though this idea is likely very false-positive prone.\r\n\r\nBelow is a screenshot from [\\[3\\]](https://webglreport.com) WebGLReport a website dedicated to fingerprinting WebGL.\r\n\r\n![VirtualBox Windows 10 x64 VM Google Chrome Visiting webglreport.com](https://bannedit.github.io/resources/VirtualBox-VM-Win10-Chrome.png) \r\n> ***VirtualBox Windows 10 x64 VM Google Chrome Visiting webglreport.com***\r\n\r\nNow, it is important to note that this depends on how the VM is configured. In Virtual Box for example, setting the graphics controller setting under Display to VMSVGA will report cause WebGL to use CPU based implementations of OpenGL which is browser dependent. However, this could still be a useful indicator that the client machine is running in a VM because most modern hardware has integrated GPUs and can provide access to OpenGL natively. Just keep in mind that CPU based OpenGL implementations do not necessarily mean it is a VM outright.\r\n\r\n![VirtualBox Windows 10 x64 VM Google Chrome Using VMSVGA](https://bannedit.github.io/resources/VirtualBox-VM-Win10-Chrome-VMSVGA.png) \r\n> ***VirtualBox Windows 10 x64 VM Google Chrome Using VMSVGA***\r\n\r\nThis screenshot depicts Google Chrome utilizing the CPU based OpenGL implementation renderer Google SwiftShader [\\[4\\]](https://github.com/google/swiftshader).\r\n\r\nAnother technique seen in normal malware is to determine the screen width and height. This can be achieved in Javascript as well. Additionally, color depth and bits per pixel are other potentially good indicators related to the display.\r\n\r\n```javascript\r\nvar width \\= screen.width;\r\nvar height \\= screen.height;\r\nvar color\\_depth \\= screen.colorDepth;\r\nvar bitspp \\= screen.pixelDepth;\r\n```\r\n\r\nMore details on the screen object can be found at [\\[5\\]](https://www.w3schools.com/jsref/obj_screen.asp).\r\n\r\nCan we detect the amount of RAM on the client? You bet. Again using Javascript we can determine roughly the amount of RAM available on the browser. One quirk to note here is that the browser will only report RAM values in gigabytes (gb). It also has a quirk where it will only report up to 8gb and as low as 256mb (0.25gb). These ranges of values however, are still enough to use as a VM detection method. Most physical workstations these days come with at least 8gb of RAM. Detecting smaller amounts of RAM such as 2gb or less would be a good indicator the client browser is in a VM. The specification for the Device Memory can be found at [\\[6\\]](https://www.w3.org/TR/device-memory/)\r\n\r\nvar ram \\= navigator.deviceMemory;\r\n\r\nFinally, the last technique I will be covering detects the number of CPU cores. This is done by performing timing attacks using multiple web workers running simultaneously. During my testing of this technique I found it to be very accurate. I tested this concept out using the [\\[7\\]](https://oswg.oftn.org/projects/core-estimator/demo/) Core Estimator Demo site. A small number of CPU cores can be a decent VM indicator and has been used by malware in the past. Core Estimator also provides the Javascript libraries on github [\\[8\\]](https://github.com/oftn-oswg/core-estimator).\r\n\r\n![VirtualBox Windows 10 x64 VM Chrome With 2 CPU Cores](https://bannedit.github.io/resources/VirtualBox-VM-Win10-Chrome-2-Cores.png) \r\n> ***VirtualBox Windows 10 x64 VM Chrome With 2 CPU Cores***\r\n\r\n### Conclusion\r\n\r\nThis blog post covered four unique VM detection capabilities that can be performed from Javascript. When I first discovered these techniques my initial thought was to apply the concepts toward VM detection. Hopefully, both defenders and offensive security professions can find something useful to apply these techniques toward.\r\n\r\nIt is interesting to see that academics and various other researchers have applied some of the same concepts toward fingerprinting and privacy issues.\r\n\r\n### References\r\n\r\n1.  (Cross-)Browser Fingerprinting via OS and Hardware Level Features [http://yinzhicao.org/TrackingFree/crossbrowsertracking\\_NDSS17.pdf](http://yinzhicao.org/TrackingFree/crossbrowsertracking_NDSS17.pdf)\r\n    \r\n2.  MDN web-docs WEBGL\\_debug\\_renderer\\_info [https://developer.mozilla.org/en-US/docs/Web/API/WEBGL\\_debug\\_renderer\\_info](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_debug_renderer_info)\r\n    \r\n3.  WebGL Report [https://webglreport.com](https://webglreport.com)\r\n    \r\n4.  Google Swiftshader Github [https://github.com/google/swiftshader](https://github.com/google/swiftshader)\r\n    \r\n5.  W3 Device Memory Specification [https://www.w3.org/TR/device-memory/](https://www.w3.org/TR/device-memory/)\r\n    \r\n6.  W3 Schools - The Screen Object [https://www.w3schools.com/jsref/obj\\_screen.asp](https://www.w3schools.com/jsref/obj_screen.asp)\r\n    \r\n7.  Core Estimator Demo [https://oswg.oftn.org/projects/core-estimator/demo/](https://oswg.oftn.org/projects/core-estimator/demo/)\r\n    \r\n8.  Core Estimator Github [https://github.com/oftn-oswg/core-estimator](https://github.com/oftn-oswg/core-estimator)","slug":"post-3"},{"frontmatter":{"title":"How to Build a Bot Detection Script From Scratch: A Step-by-Step Guide","description":"Bot Detection","image":"/images/posts/09.png","date":"2024-06-12T00:00:00.000Z","draft":false,"authors":["Mark Dinn"],"tags":["Bot","Web"],"categories":["Javascript"]},"content":"\r\nDid you know an estimated half of all web traffic comes from bots? And over half of that automated traffic is from \"bad bots.\" Websites constantly face threats from automated bots designed to carry out malicious activities like credential stuffing attacks, web scraping, spam distribution, and fraud.\r\n\r\nAccurately distinguishing this automated bot traffic from genuine human traffic is critical to protecting websites, user data, and online assets. As these bots continue to evolve, businesses must add robust measures to detect and mitigate bot attacks effectively and keep up with the latest bot technology.\r\n\r\nMany methods exist to identify potential bot activity, whether you are analyzing network and traffic patterns, user browsers and device information, or behavior patterns. These methods allow you to take immediate action and prevent data breaches, protect user privacy, and ensure the integrity of your website.\r\n\r\nThis step-by-step guide for client-side bot detection explores common techniques for identifying bot activity. By the end of this tutorial, you'll have gained hands-on experience in building a basic bot detection script and learn practical methods to distinguish human visitors from malicious bots and protect your site.\r\n\r\nUnderstanding bots\r\nBots are automated programs that can execute tasks and interactions over the internet by mimicking human behavior. These programs visit websites and apps and perform predefined actions, usually in a “headless” mode without a graphical interface.\r\n\r\nOn the one hand, bots facilitate many legitimate functions, such as web crawling for search engines, data collection for research, website performance monitoring, and automating repetitive online tasks.\r\n\r\nHowever, bad actors can also use bots for malicious purposes, such as trying countless username/password combinations, illicitly scraping proprietary data or copyrighted content, launching distributed denial of service (DDoS) attacks, and spreading spam or malware.\r\n\r\nFundamentals of bot detection\r\nBot detection strategies can be broadly categorized into server-side and client-side techniques, each harnessing different methods to identify and manage bot traffic.\r\n\r\nServer-side detection uses your backend to analyze data like IP addresses, HTTP headers, and session durations. Common methods include:\r\n\r\nIP Blocklists: Checking user IP addresses against lists of known IPs or bot networks associated with malicious activity.\r\nRate Limiting: Monitoring the frequency of requests to identify and mitigate unusually high traffic from single sources, usually indicative of bots.\r\nBehavioral Analysis: Assessing access and interactions over time to detect anomalies in behavior that deviate from human patterns.\r\nClient-side detection operates within the user's browser and analyzes user behaviors and environmental data in real-time. Some client-side methods include:\r\n\r\nCAPTCHAs: Challenges that differentiate bots from humans by asking visitors to do tasks that are trivial for humans but difficult for bots.\r\nBrowser Analysis: Gathering and analyzing browser configurations and capabilities to identify patterns or inconsistencies typical of automated scripts.\r\nBehavioral Analysis: Monitoring actions like mouse movements, keystrokes, and interaction timings to detect non-human activity.\r\nThis guide will focus on client-side techniques, mainly how scripts can analyze the inadvertent data bots emit as they interact with a webpage. These leaks may manifest as anomalies in interaction patterns, browser settings, or how a page's layout is processed. By examining these factors, we can develop scripts that identify potential bots. This approach allows for rapid, on-the-spot bot detection, enhancing user experience by minimizing intrusive checks and maintaining performance efficiency.\r\n\r\nBuilding a basic bot detection script\r\nLet's start building a basic bot detection script for a sample application. This tutorial will use vanilla JavaScript to keep it accessible to a broad audience and various web environments. The objective of our application is simple: to analyze specific data from the visitor's browser to determine whether they are likely a bot. We'll do this by collecting data, analyzing them against common bot patterns, and sending a message in the application indicating if the script detected a bot. This example will showcase how client-side scripts can assess environmental signals to make this distinction and will not include server-side processing.\r\n\r\nPrerequisites\r\n\r\nTo follow along with the tutorial locally, you must have Node.js installed on your machine and a code editor like Visual Studio Code. You can also use a cloud development environment like Stackblitz or CodeSandbox.\r\n\r\nSet up the sample web application\r\nTo begin creating our bot detection script, we first need a simple web application where we will integrate it.\r\n\r\n1. Create the project structure\r\n\r\nStart by creating a new directory for your project. Inside this directory, create the following files:\r\n\r\nindex.html: This will be the main HTML document.\r\nscript.js: This JavaScript file will hold our bot detection logic.\r\nYour project directory should look like this:\r\n\r\n```javascript\r\nbot-detection-app/\r\n|-- index.html\r\n|-- script.js\r\n```\r\n\r\n1. Set up the HTML file\r\n\r\nOpen the index.html file and set up the basic HTML structure, including linking to the script.js file. We’ll be using tailwind for some simple styling. Here’s a simple template to start with:\r\n\r\n\r\n``` html\r\n<html lang=\"en\">\r\n  <head>\r\n    <meta charset=\"UTF-8\" />\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\r\n    <link\r\n      rel=\"icon\"\r\n      href=\"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%221em%22 font-size=%2280%22>🤖</text></svg>\"\r\n    />\r\n    <title>Simple Bot Detection App</title>\r\n    <script src=\"https://cdn.tailwindcss.com\"></script>\r\n    <script src=\"script.js\" defer></script>\r\n  </head>\r\n  <body class=\"bg-gray-100 text-gray-900 min-h-screen pt-20 text-center\">\r\n    <h1 class=\"text-4xl font-bold mb-4\">🤖</h1>\r\n    <h1 class=\"text-2xl font-bold mb-4\">Bot Detection Sample Application</h1>\r\n    <div id=\"result\" class=\"text-xl font-medium\"></div>\r\n  </body>\r\n</html>\r\n```\r\n\r\n1. Serve and preview the application\r\n\r\nYou can use a simple HTTP server to run the sample web application locally and preview it in your browser. A simple way to do this is with http-server, an easy-to-use zero-configuration command-line HTTP server great for quickly serving static files. First, install the package:\r\n\r\nnpm install -g http-server\r\nThen navigate to your project directory in the terminal and run:\r\n\r\nhttp-server\r\nNote: You can also install this as a local project dependency with npm install http-server and run it with npx http-server instead.\r\n\r\nThe HTTP server will serve your project, making it available at http://localhost:8080. Open this URL in your browser to view the application as you work.\r\n\r\nWith these steps completed, you have set up a simple web application that is ready to implement bot detection functionalities. This setup will allow us to focus now on collecting data and determining if a visitor might be a bot in the upcoming sections of the tutorial.\r\n\r\nCollect and analyze visitor data\r\nIn this section, we'll focus on collecting data that we will use to determine if a visitor might be a bot. We will gather browser characteristics often exploited or modified by bots that serve as good indicators. Create a new detectBot function with a detectors object to store each detected signal.\r\n\r\n```javascript\r\nfunction detectBot() {\r\n  const detectors = {};\r\n}\r\n```\r\n\r\n1. Detect WebDriver automation\r\n\r\nOne of the simplest places to find signals for bot detection is to look at the Navigator object. This object is a part of the Window interface and represents the state and identity of the user's browser. It has information about the browser itself, including its version, the operating system it's running on, and various capabilities of the browser environment.\r\n\r\nWithin the navigator object, the webdriver property is especially useful as it indicates whether the browser is being controlled by automation tools such as Selenium, Puppeteer, or other automated testing frameworks. Unlike many other indicators that require interpretation or analysis, these tools typically set the navigator.webdriver property to true to indicate automation control. Add this property to the detectors object.\r\n\r\n```javascript\r\nfunction detectBot() {\r\n  const detectors = {\r\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\r\n  };\r\n}\r\n```\r\n\r\nAs we progress, we will add more properties to the detectors object to collect additional data from different aspects of the visitor's environment that may indicate bot activity. Starting with navigator.webdriver establishes a solid foundation for recognizing the most obvious automated interactions.\r\n\r\n1. Look for Headless Chrome\r\n\r\nThe navigator.userAgent property is another valuable piece of data for bot detection. This user agent string identifies the browser, its version, the underlying operating system, and sometimes other details about the device. Looking at the user agent can help determine whether the traffic originates from common headless browsers that might be used for scraping, automation, or other scripted activities. Add a check for the user agent that looks for “Headless”, a common value found in the most common tools used for automated tasks on the web. You can also check for other tools with string searches for values like “PhantomJS” or “Electron”.\r\n\r\n```javascript\r\nfunction detectBot() {\r\n  const detectors = {\r\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\r\n    headlessBrowser: navigator.userAgent.includes(\"Headless\"), // Detects headless browsers\r\n  };\r\n}\r\n```\r\n\r\nThe webdriver and userAgent properties can cover quite a large amount of bot activity already, but the more indicators you analyze, the more accurate your bot detection can become. Especially since many automation tools add features and settings that try to evade common bot detection techniques. Let’s continue to add a few more helpful detector examples.\r\n\r\n1. Check for missing preferred language\r\n\r\nOne potential indicator of a bot is the lack of set languages. The navigator.languages property returns a list of the user's preferred languages ordered by preference, with the most preferred language (first in the list) also set as the navigator.language property. However, the navigator.languages property sometimes returns an empty string in headless browsers. We’ll add the length of this property as a new signal for our bot detection.\r\n\r\n```javascript\r\nfunction detectBot() {\r\n  const detectors = {\r\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\r\n    headlessBrowser: navigator.userAgent.includes(\"Headless\"), // Detects headless browsers\r\n    noLanguages: (navigator.languages?.length || 0) === 0, // Checks if no languages are set, uncommon for regular users\r\n  };\r\n}\r\n```\r\n\r\n1. Evaluate expected browser features\r\n\r\nYou can also check the properties of JavaScript functions that are sometimes altered by automation scripts or in a headless environment. Bots can easily change user agent strings, so this check looks to see if there is a mismatch between the browser from the user agent and the features that should be available for that browser. For example, you can check the length of the eval function and compare it to what is expected for that browser.\r\n\r\nThis check requires more work, first detecting the browser and then comparing the appropriate length values. Let’s add a new function to do this check and use the returned result for our inconsistentEval detector.\r\n\r\n```javascript\r\nfunction detectBot() {\r\n  const detectors = {\r\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\r\n    headlessBrowser: navigator.userAgent.includes(\"Headless\"), // Detects headless browsers\r\n    noLanguages: (navigator.languages?.length || 0) === 0, // Checks if no languages are set, uncommon for regular users\r\n    inconsistentEval: detectInconsistentEval(), // Check for inconsistent eval lengths\r\n  };\r\n}\r\n\r\nfunction detectInconsistentEval() {\r\n  let length = eval.toString().length;\r\n  let userAgent = navigator.userAgent.toLowerCase();\r\n  let browser;\r\n\r\n  if (userAgent.indexOf(\"edg/\") !== -1) {\r\n    browser = \"edge\";\r\n  } else if (\r\n    userAgent.indexOf(\"trident\") !== -1 ||\r\n    userAgent.indexOf(\"msie\") !== -1\r\n  ) {\r\n    browser = \"internet_explorer\";\r\n  } else if (userAgent.indexOf(\"firefox\") !== -1) {\r\n    browser = \"firefox\";\r\n  } else if (\r\n    userAgent.indexOf(\"opera\") !== -1 ||\r\n    userAgent.indexOf(\"opr\") !== -1\r\n  ) {\r\n    browser = \"opera\";\r\n  } else if (userAgent.indexOf(\"chrome\") !== -1) {\r\n    browser = \"chrome\";\r\n  } else if (userAgent.indexOf(\"safari\") !== -1) {\r\n    browser = \"safari\";\r\n  } else {\r\n    browser = \"unknown\";\r\n  }\r\n\r\n  if (browser === \"unknown\") return false;\r\n\r\n  return (\r\n    (length === 33 && ![\"chrome\", \"opera\", \"edge\"].includes(browser)) ||\r\n    (length === 37 && ![\"firefox\", \"safari\"].includes(browser)) ||\r\n    (length === 39 && ![\"internet_explorer\"].includes(browser))\r\n  );\r\n}\r\n```\r\n\r\n1. Look for automation-related attributes\r\n\r\nSome automation tools add specific attributes to the DOM. Looking for these attributes can be useful for detecting specific automation tools, like Selenium, which may leave traces in the form of custom attributes. Let’s add another data point to our bot detection that gets the attributes of the document's root element and looks for properties commonly associated with automation tools.\r\n\r\n```javascript\r\nfunction detectBot() {\r\n  const detectors = {\r\n    webDriver: navigator.webdriver, // Checks if the browser is controlled by automation\r\n    headlessBrowser: navigator.userAgent.includes(\"Headless\"), // Detects headless browsers\r\n    noLanguages: (navigator.languages?.length || 0) === 0, // Checks if no languages are set, uncommon for regular users\r\n    inconsistentEval: detectInconsistentEval(), // Check for inconsistent eval lengths\r\n    domManipulation: document.documentElement\r\n      .getAttributeNames()\r\n      .some((attr) => [\"selenium\", \"webdriver\", \"driver\"].includes(attr)), // Looks for attributes commonly added by automation tools\r\n  };\r\n}\r\n```\r\n\r\nThese are just a handful of example signals that you can use to identify bots, and the more sophisticated the bot, the more signals you will need to check to detect it. Using this data, let's look at how you can now detect if a visitor is a bot.\r\n\r\nDetect the presence of a bot\r\nAfter gathering the necessary data points about the visitor's environment, the next step is to analyze this information to determine whether the visitor is likely a bot. We can loop through each detector, and if a signal for a bot is found, we’ll record which detector was flagged and set our bot verdict to true.\r\n\r\n```javascript\r\nfunction detectBot() {\r\n  const detectors = {\r\n    …\r\n  };\r\n\r\n  // 1. Stores the detection results and the final verdict\r\n  const detections = {};\r\n  let verdict = { bot: false };\r\n\r\n  // 2. Iterates over the detectors and sets the verdict to true if any of them detects bot-like activity\r\n  for (const detectorName in detectors) {\r\n    const detectorResult = detectors[detectorName];\r\n    detections[detectorName] = { bot: detectorResult };\r\n    if (detectorResult) {\r\n      verdict = { bot: true }; // Sets the verdict to true at the first detection of bot-like activity\r\n    }\r\n  }\r\n\r\n  // 3. Returns the detection results and the final verdict\r\n  return { detections, verdict };\r\n}\r\n```\r\n\r\nThe new additions to the detectBot function:\r\n\r\nCreates variables to store the bot detection results and a verdict.\r\nLoops through each detector, and if a bot signal is found, it is added to the detections list and sets the verdict to true.\r\nReturns the list of detections and the final bot verdict.\r\nUse the bot detection result\r\nAt this point, you can decide how to handle the visitor based on your bot detection result. This tutorial will display the result on the page and log the detections and verdict in the console. Add the following after your function declarations.\r\n\r\n```javascript\r\nfunction detectBot() {\r\n\t...\r\n}\r\n\r\nfunction detectInconsistentEval() {\r\n\t...\r\n}\r\n\r\nconst { detections, verdict } = detectBot();\r\ndocument.getElementById('result').innerText = verdict.bot ? 'Bot detected' : 'No bot detected'; // Displays the detection result on the web page\r\nconsole.log(JSON.stringify(verdict, null, 2)); // Logs the final verdict\r\nconsole.log(JSON.stringify(detections, null, 2)); // Logs detailed detections\r\n```\r\n\r\nTest the bot detection\r\nNow, we can visit our page and see the result of our bot detection script. If you followed along locally, ensure the http-server is running and visit http://localhost:8080 in your browser. If you are using a cloud IDE, visit the preview page provided for your project. You should see the result “No bot detected” displayed on the screen. You can also see the verdict and details in the developer console.\r\n\r\nScreenshot of the final bot detection sample app\r\n\r\nNow, let’s test the script using a bot. Within your root folder in a new terminal, we’ll add Puppeteer to test our basic bot detection.\r\n\r\nnpm install puppeteer\r\nNext, create a new file called bot_test.js with the following code to run Puppeteer and test out your application.\r\n\r\n```javascript\r\nconst puppeteer = require(\"puppeteer\");\r\n\r\n(async function testBot() {\r\n  const url = \"http://localhost:8080\";\r\n  const browser = await puppeteer.launch();\r\n  const page = await browser.newPage();\r\n  // Log console messages from the page\r\n  page.on(\"console\", (message) =>\r\n    console.log(`${message.type().toUpperCase()} ${message.text()}`)\r\n  );\r\n  await page.goto(url);\r\n  await page.close();\r\n  await browser.close();\r\n})();\r\n```\r\n\r\nIn this file, we use the Puppeteer library to launch a headless browser and navigate to your local application. You’ll notice there is a line to display any console messages from the page in your terminal to see the output of the verdict and detections. If you are following along in a cloud IDE, make sure to use the appropriate URL.\r\n\r\nNow that the script is ready, in your new terminal at the root, run the bot_test.js script.\r\n\r\nnode bot_test.js\r\nOptionally, you can use our instance of Browserless to visit your public-facing project link as a bot.\r\n\r\nYou will see the verdict and detections shown from the console log and should see an output similar to the one below that shows a bot was detected.\r\n\r\n```javascript\r\nLOG {\r\n\t\"bot\": true\r\n}\r\n\r\nLOG {\r\n  \"webDriver\": {\r\n    \"bot\": true\r\n  },\r\n\r\n  \"headlessBrowser\": {\r\n    \"bot\": true\r\n  },\r\n\r\n  \"noLanguages\": {\r\n    \"bot\": false\r\n  },\r\n\r\n  \"inconsistentEval\": {\r\n    \"bot\": false\r\n  },\r\n\r\n  \"domManipulation\": {\r\n    \"bot\": false\r\n  }\r\n}\r\n```\r\n\r\nThis sample tutorial simply displays the result of the bot detection, but you can easily incorporate the verdict into your application to decide how to handle the visitor.\r\n\r\nImproving your bot detection\r\nWhile the basic bot detection script provided earlier serves as an introduction to identifying automated traffic, it naturally has limitations that could affect its use in more demanding or varied environments:\r\n\r\nLimited Scope: The script checks only a handful of potential indicators, such as navigator.webdriver, user agent content for \"Headless\", and a few others. This narrow focus can miss more sophisticated bots that do not trigger these specific detectors.\r\n\r\nTool Specificity: Some of the checks, like looking for \"Headless\", are tailored to detect specific types of automation tools. While effective against those, they won't catch bots using different tools or customized solutions that don't modify the user agent string or use different mechanisms.\r\n\r\nBrowser Dependency: The detection techniques used can be highly dependent on the behaviors of specific browsers. Some indicators can have legitimate differences and variances with their implementations. Keeping up with these variations across updates and different browsers adds complexity and maintenance overhead.\r\n\r\nDynamic Web Ecosystem: Browsers and bot technologies evolve quickly. A method that works today might become obsolete tomorrow as both browsers update their features for privacy and security, and bot operators update their tools to evade detection.\r\n\r\nSuggestions for script improving accuracy\r\nTo boost the accuracy and reliability of your bot detection mechanisms, consider extending your script beyond basic checks. By combining different types of data points and detection methods, you can create a more robust defense against various bot activities. For example, integrating behavioral analysis—such as monitoring mouse movements, keystrokes, and even scrolling behaviors—can help identify bots that might otherwise pass more static checks. These behavioral signals are often more difficult for bots to convincingly mimic and can reveal the non-human characteristics of their interactions.\r\n\r\nAdditionally, keeping your detection methods up-to-date is essential. As browsers evolve and bot operators refine their techniques, your detection strategies must also adapt. Regular updates to your scripts to align with the latest browser versions and known bot signatures ensure that your detection mechanisms remain effective against current and emerging threats.\r\n\r\nUsing the open-source BotD library\r\nFor those looking to improve their bot detection capabilities without the burden of developing and maintaining a complex in-house system, the open-source BotD bot detection library presents a robust and user-friendly alternative.\r\n\r\nBotD provides more comprehensive coverage, incorporating more detection techniques that address multiple bot behaviors. Being an open-source library, it can easily be added to websites to increase defenses against bot traffic, minimizing the technical challenges typically associated with detecting bots.\r\n","slug":"post-4"},{"frontmatter":{"title":"Crafting a Uniform Response Structure in NestJS: A Guide to Mastering Interceptors","description":"Streamlining API Development with Powerful Interceptor Techniques","image":"/images/posts/05.jpg","date":"2024-07-02T00:00:00.000Z","draft":false,"authors":["Stackademic"],"tags":["NestJS","Javascript"],"categories":["Javascript"]},"content":"\r\nIn the rapidly evolving domain of web development, maintaining a uniform response structure plays a pivotal role in building a robust and scalable application, especially when it comes to creating an API ecosystem that interacts with various services and components. A uniform response structure not only ensures consistency across services but also facilitates enhanced error handling, easier maintenance, and efficient logging and monitoring. Before we delve into a hands-on demonstration, let’s discuss why having a uniform response structure is significant.\r\n\r\n### Significance of a Uniform Response Structure\r\n\r\nA uniform response structure stands as a cornerstone in constructing an efficient and seamless API experience. Here’s why it’s vital:\r\n\r\n1.  Consistency Across Services: It guarantees that every service communicates using a standard language, enhancing interoperability and facilitating a smoother integration process, particularly in microservices architectures.\r\n2.  Enhanced Error Handling: A standard response format means standardized error handling. It assists in crafting user-friendly error messages, improving the user experience by presenting clear and uniform error responses.\r\n3.  Ease of Maintenance and Scalability: As your application grows, maintaining a uniform response structure ensures that the integration of new features or services is seamless, preventing potential disparities in response formats and thereby reducing the maintenance overhead.\r\n4.  Efficient Monitoring and Logging: Uniform responses allow monitoring tools to be configured more effectively, helping in the setup of analytics and logging systems that provide critical insights into API performance and usage trends.\r\n\r\nUnderstanding its significance, let’s move forward to set up a uniform response structure using NestJS interceptors in our sample project.\r\n\r\n### Setting up Your NestJS Project\r\n\r\nBefore we start crafting our interceptor, let’s ensure that you have the necessary setup ready. Firstly, install the Nest CLI globally using the following command:\r\n\r\n```bash\r\nnpm install -g @nestjs/cli\r\n```\r\n\r\nNext, leverage the power of the Nest CLI to create a new project named `sample-interceptor-example` and navigate into your project directory as shown below:\r\n\r\nnest new sample-interceptor-example  \r\ncd sample-interceptor-example\r\n\r\n### Generating and Setting up the Interceptor\r\n\r\nWith your project setup ready, it’s time to create an interceptor. Generate a new interceptor named ‘response’ using the following command:\r\n\r\n```bash\r\nnest g itc response\r\n```\r\n\r\nThis command generates a boilerplate interceptor file with the following structure:\r\n\r\n```javascript\r\nimport { CallHandler, ExecutionContext, Injectable, NestInterceptor } from '@nestjs/common';  \r\nimport { Observable } from 'rxjs';  \r\n  \r\n@Injectable()  \r\nexport class ResponseInterceptor implements NestInterceptor {  \r\n  intercept(context: ExecutionContext, next: CallHandler): Observable<any\\> {  \r\n    return next.handle();  \r\n  }  \r\n}\r\n```\r\n\r\nNow, we will enhance this interceptor to handle both successful and erroneous responses uniformly.\r\n\r\n### Modifying the Interceptor\r\n\r\nLet’s modify the `intercept` method in our interceptor to pipe through our custom response and error handlers. Here is how you can do it:\r\n\r\n```javascript\r\n  intercept(context: ExecutionContext, next: CallHandler): Observable<unknown\\> {  \r\n    return next.handle().pipe(  \r\n      map((res: unknown) => this.responseHandler(res, context)),  \r\n      catchError((err: HttpException) => throwError(() => this.errorHandler(err, context)))  \r\n    );  \r\n  }\r\n```\r\n\r\nIn the above snippet, we are using the `map` operator to handle successful responses and the `catchError` operator to handle errors uniformly. Let's proceed to implement these handlers.\r\n\r\n### Implementing the Error Handler\r\n\r\nThe error handler is designed to catch any exceptions that occur during the request lifecycle and return a standardized error response. Here is how you can implement it:\r\n\r\n```javascript\r\n  errorHandler(exception: HttpException, context: ExecutionContext) {  \r\n    const ctx = context.switchToHttp();  \r\n    const response = ctx.getResponse();  \r\n    const request = ctx.getRequest();  \r\n  \r\n    const status = exception instanceof HttpException ? exception.getStatus() : HttpStatus.INTERNAL\\_SERVER\\_ERROR;  \r\n  \r\n    response.status(status).json({  \r\n      status: false,  \r\n      statusCode: status,  \r\n      path: request.url,  \r\n      message: exception.message,  \r\n      result: exception,  \r\n    });  \r\n  }\r\n```\r\n\r\nIn this method, we first retrieve the HTTP context and then determine the appropriate status code for the error. Next, we construct a standardized error response containing various details like the request URL, status code, and error message.\r\n\r\n### Implementing the Response Handler\r\n\r\nSimilarly, we will create a response handler to process successful responses uniformly. Here is the implementation:\r\n\r\n```javascript\r\n  responseHandler(res: any, context: ExecutionContext) {  \r\n    const ctx = context.switchToHttp();  \r\n    const response = ctx.getResponse();  \r\n    const request = ctx.getRequest();  \r\n  \r\n    const statusCode = response.statusCode;  \r\n  \r\n    return {  \r\n      status: true,  \r\n      path: request.url,  \r\n      statusCode,  \r\n      result: res,  \r\n    };  \r\n  }\r\n```\r\n\r\nThis method, much like the error handler, retrieves the HTTP context and constructs a standardized response with a success status, the request URL, status code, and the result data.\r\n\r\n### Integrating the Interceptor in Your Application\r\n\r\nAfter modifying and implementing the necessary handlers in our interceptor, we have the following combined code structure:\r\n\r\n```javascript\r\nimport { Injectable, NestInterceptor, ExecutionContext, CallHandler, HttpException, HttpStatus } from '@nestjs/common';  \r\nimport { Observable, throwError } from 'rxjs';  \r\nimport { catchError, map } from 'rxjs/operators';  \r\n  \r\n@Injectable()  \r\nexport class ResponseInterceptor implements NestInterceptor {  \r\n  intercept(context: ExecutionContext, next: CallHandler): Observable<unknown\\> {  \r\n    return next.handle().pipe(  \r\n      map((res: unknown) => this.responseHandler(res, context)),  \r\n      catchError((err: HttpException) => throwError(() => this.errorHandler(err, context)))  \r\n    );  \r\n  }  \r\n  \r\n  errorHandler(exception: HttpException, context: ExecutionContext) {  \r\n    const ctx = context.switchToHttp();  \r\n    const response = ctx.getResponse();  \r\n    const request = ctx.getRequest();  \r\n  \r\n    const status = exception instanceof HttpException ? exception.getStatus() : HttpStatus.INTERNAL\\_SERVER\\_ERROR;  \r\n  \r\n    response.status(status).json({  \r\n      status: false,  \r\n      statusCode: status,  \r\n      path: request.url,  \r\n      message: exception.message,  \r\n      result: exception,  \r\n    });  \r\n  }  \r\n  \r\n  responseHandler(res: any, context: ExecutionContext) {  \r\n    const ctx = context.switchToHttp();  \r\n    const response = ctx.getResponse();  \r\n    const request = ctx.getRequest();  \r\n  \r\n    const statusCode = response.statusCode;  \r\n  \r\n    return {  \r\n      status: true,  \r\n      path: request.url,  \r\n      statusCode,  \r\n      result: res,  \r\n    };  \r\n  }  \r\n}\r\n```\r\n\r\nNow, to make our interceptor work, we need to integrate it into our NestJS application. Open the `main.ts` file in your project and include the following line inside the `bootstrap` function:\r\n\r\n```javascript\r\napp.useGlobalInterceptors(new ResponseInterceptor());\r\n```\r\n\r\nWith this addition, our interceptor is now active globally across our application. Run your application and witness the transformation in the API response structure — it’s harmonized, clean, and efficient, ensuring a streamlined user experience and facilitating easier maintenance and scalability.\r\n\r\n### Conclusion\r\n\r\nStepping back and evaluating what we’ve built, it’s clear to see the tangible benefits that implementing a uniform response structure can bring to a NestJS project. It streamlines the development process, facilitates debugging, and fosters a cleaner, more maintainable codebase.\r\n\r\nAs you continue your journey with NestJS, keep exploring its robust ecosystem and making the most of tools like interceptors. They not only tidy up your code but also prepare you for scaling your project in a manageable way. With a consistent response structure in place, you’ll find it easier to develop, maintain, and evolve your application effectively.\r\n\r\nHappy coding!\r\n\r\n### Stackademic\r\n","slug":"post-5"},{"frontmatter":{"title":"Become a morning person with the help of this a alarm clock","description":"meta description","image":"/images/posts/06.jpg","date":"2021-02-03T00:00:00.000Z","draft":false,"authors":["Mark Dinn"],"tags":["Alarm","Clock"],"categories":["LifeStyle"]},"content":"\r\nAlmost every day for the past nine or so months has felt like March 13, and that can sometimes make it difficult to want to wake up for the day ahead of you.\r\n\r\nTo make a morning person out of you, the wake-up light simulates the sunrise to gradually ease you awake. This allows you to wake up more naturally rather than being jolted awake by the default iPhone alarm sound, which honestly triggers my fight or flight response.\r\n\r\n### Creative Design\r\n\r\nNam ut rutrum ex, venenatis sollicitudin urna. Aliquam erat volutpat. Integer eu ipsum sem. Ut bibendum lacus vestibulum maximus suscipit. Quisque vitae nibh iaculis neque blandit euismod.\r\n\r\n>Lorem ipsum dolor sit amet consectetur adipisicing elit. Nemo vel ad consectetur ut aperiam. Itaque eligendi natus aperiam? Excepturi repellendus consequatur quibusdam optio expedita praesentium est adipisci dolorem ut eius!\r\n\r\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo vel ad consectetur ut aperiam. Itaque eligendi natus aperiam? Excepturi repellendus consequatur quibusdam optio expedita praesentium est adipisci dolorem ut eius!\r\n","slug":"post-6"},{"frontmatter":{"title":"DIY Paper Diamond Tutorial with HUNGRY HEART","description":"meta description","date":"2022-08-12T00:00:00.000Z","image":"/images/posts/04.jpg","categories":["art"],"authors":["Mark Dinn"],"tags":["diy","toy"],"draft":false},"content":"\r\nNemo vel ad consectetur namut rutrum ex, venenatis sollicitudin urna. Aliquam erat volutpat. Integer eu ipsum sem. Ut bibendum lacus vestibulum maximus suscipit. Quisque vitae nibh iaculis neque blandit euismod.\r\n\r\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo vel ad consectetur ut aperiam. Itaque eligendi natus aperiam? Excepturi repellendus consequatur quibusdam optio expedita praesentium est adipisci dolorem ut eius!\r\n\r\n## Creative Design\r\n\r\nNam ut rutrum ex, venenatis sollicitudin urna. Aliquam erat volutpat. Integer eu ipsum sem. Ut bibendum lacus vestibulum maximus suscipit. Quisque vitae nibh iaculis neque blandit euismod.\r\n\r\n> Lorem ipsum dolor sit amet consectetur adipisicing elit. Nemo vel ad consectetur ut aperiam. Itaque eligendi natus aperiam? Excepturi repellendus consequatur quibusdam optio expedita praesentium est adipisci dolorem ut eius!\r\n\r\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo vel ad consectetur ut aperiam. Itaque eligendi natus aperiam? Excepturi repellendus consequatur quibusdam optio expedita praesentium est adipisci dolorem ut eius!\r\n","slug":"post-7"}]